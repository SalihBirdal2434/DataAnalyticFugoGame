{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:09.726930Z",
     "start_time": "2024-09-12T14:07:09.706375Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:16.829114Z",
     "start_time": "2024-09-12T14:07:09.839582Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pycaret.regression import setup, compare_models\n",
    "import logging\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "trainUsers=pd.read_csv(\"users_train.csv\")\n",
    "trainUsers.drop(\"ID\",axis=1,inplace=True)\n",
    "testUsers=pd.read_csv(\"users_test.csv\")\n",
    "testUsers.drop(\"ID\",axis=1,inplace=True)\n",
    "trainFeatures=pd.read_csv(\"user_features_train.csv\")\n",
    "testFeatures=pd.read_csv(\"user_features_test.csv\")\n",
    "target=pd.read_csv(\"targets_train.csv\")\n",
    "train=[trainUsers,trainFeatures,target]\n",
    "test=[testUsers,testFeatures]\n",
    "train=pd.concat(train,axis=1)\n",
    "test=pd.concat(test,axis=1)\n",
    "\n",
    "\n",
    "ID=test[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:18.072942Z",
     "start_time": "2024-09-12T14:07:16.830181Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_datetime_features(df):\n",
    "    # `first_open_date` ve `first_open_timestamp` sütunlarının tarih formatında olduğundan emin olun\n",
    "    df['first_open_date'] = pd.to_datetime(df['first_open_date'])\n",
    "    df['first_open_timestamp'] = pd.to_datetime(df['first_open_timestamp'])\n",
    "    df['local_first_open_timestamp'] = pd.to_datetime(df['local_first_open_timestamp'])\n",
    "\n",
    "    # Tarih bileşenlerini ayırın\n",
    "    df['open_year'] = df['first_open_date'].dt.year\n",
    "    df['open_month'] = df['first_open_date'].dt.month\n",
    "    df['open_day'] = df['first_open_date'].dt.day\n",
    "\n",
    "    # `microsecond` değerlerine erişim\n",
    "    df[\"micro_first_open_times\"] = df['first_open_timestamp'].dt.microsecond\n",
    "    df[\"local_micro_first_open_times\"] = df['local_first_open_timestamp'].dt.microsecond\n",
    "\n",
    "    # Orijinal datetime sütunlarını kaldırın\n",
    "    df = df.drop(columns=['first_open_date', 'first_open_timestamp', 'local_first_open_timestamp'],inplace=True)\n",
    "\n",
    "    return df\n",
    "process_datetime_features(train)\n",
    "process_datetime_features(test)\n",
    "process_datetime_features(testUsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:18.151569Z",
     "start_time": "2024-09-12T14:07:18.073933Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainUserscopy=trainUsers.iloc[:10000]\n",
    "testUserscopy=testUsers.iloc[:10000]\n",
    "trainFeaturescopy=trainFeatures.iloc[:10000]\n",
    "testFeaturescopy=testFeatures.iloc[:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:18.167069Z",
     "start_time": "2024-09-12T14:07:18.152569Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((878594, 90), (585730, 88))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:18.448288Z",
     "start_time": "2024-09-12T14:07:18.168061Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((585730, 87), (878594, 88))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(\"ID\",inplace=True,axis=1)\n",
    "test.drop(\"ID\",inplace=True,axis=1)\n",
    "\n",
    "test.shape,train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:18.995484Z",
     "start_time": "2024-09-12T14:07:18.449288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------    Information     --------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878594 entries, 0 to 878593\n",
      "Data columns (total 88 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   country                       878512 non-null  object \n",
      " 1   platform                      878594 non-null  object \n",
      " 2   device_category               878594 non-null  object \n",
      " 3   device_brand                  872754 non-null  object \n",
      " 4   device_model                  878594 non-null  object \n",
      " 5   has_ios_att_permission        878594 non-null  bool   \n",
      " 6   ad_network                    568124 non-null  object \n",
      " 7   first_prediction              852859 non-null  float64\n",
      " 8   RetentionD0                   878594 non-null  bool   \n",
      " 9   RetentionD1                   878594 non-null  bool   \n",
      " 10  RetentionD2                   878594 non-null  bool   \n",
      " 11  RetentionD3                   878594 non-null  bool   \n",
      " 12  RetentionD4                   878594 non-null  bool   \n",
      " 13  RetentionD5                   878594 non-null  bool   \n",
      " 14  RetentionD6                   878594 non-null  bool   \n",
      " 15  RetentionD7                   878594 non-null  bool   \n",
      " 16  RetentionD8                   878594 non-null  bool   \n",
      " 17  RetentionD9                   878594 non-null  bool   \n",
      " 18  RetentionD10                  878594 non-null  bool   \n",
      " 19  RetentionD11                  878594 non-null  bool   \n",
      " 20  RetentionD12                  878594 non-null  bool   \n",
      " 21  RetentionD13                  878594 non-null  bool   \n",
      " 22  RetentionD14                  878594 non-null  bool   \n",
      " 23  RetentionD15                  878594 non-null  bool   \n",
      " 24  LevelAdvancedCountD0          878594 non-null  int64  \n",
      " 25  LevelAdvancedCountD1          878594 non-null  int64  \n",
      " 26  LevelAdvancedCountD2          878594 non-null  int64  \n",
      " 27  LevelAdvancedCountD3          878594 non-null  int64  \n",
      " 28  LevelAdvancedCountD4          878594 non-null  int64  \n",
      " 29  LevelAdvancedCountD5          878594 non-null  int64  \n",
      " 30  LevelAdvancedCountD6          878594 non-null  int64  \n",
      " 31  LevelAdvancedCountD7          878594 non-null  int64  \n",
      " 32  LevelAdvancedCountD8          878594 non-null  int64  \n",
      " 33  LevelAdvancedCountD9          878594 non-null  int64  \n",
      " 34  LevelAdvancedCountD10         878594 non-null  int64  \n",
      " 35  LevelAdvancedCountD11         878594 non-null  int64  \n",
      " 36  LevelAdvancedCountD12         878594 non-null  int64  \n",
      " 37  LevelAdvancedCountD13         878594 non-null  int64  \n",
      " 38  LevelAdvancedCountD14         878594 non-null  int64  \n",
      " 39  LevelAdvancedCountD15         878594 non-null  int64  \n",
      " 40  Level_1_Duration              872494 non-null  float64\n",
      " 41  Level_2_Duration              828188 non-null  float64\n",
      " 42  Level_3_Duration              790654 non-null  float64\n",
      " 43  Level_4_Duration              728697 non-null  float64\n",
      " 44  Level_5_Duration              686832 non-null  float64\n",
      " 45  Level_6_Duration              649367 non-null  float64\n",
      " 46  Level_7_Duration              609764 non-null  float64\n",
      " 47  Level_8_Duration              577358 non-null  float64\n",
      " 48  Level_9_Duration              559933 non-null  float64\n",
      " 49  Level_10_Duration             522605 non-null  float64\n",
      " 50  AdRevenueD0                   878594 non-null  float64\n",
      " 51  AdRevenueD1                   878594 non-null  float64\n",
      " 52  AdRevenueD2                   878594 non-null  float64\n",
      " 53  AdRevenueD3                   878594 non-null  float64\n",
      " 54  AdRevenueD4                   878594 non-null  float64\n",
      " 55  AdRevenueD5                   878594 non-null  float64\n",
      " 56  AdRevenueD6                   878594 non-null  float64\n",
      " 57  AdRevenueD7                   878594 non-null  float64\n",
      " 58  AdRevenueD8                   878594 non-null  float64\n",
      " 59  AdRevenueD9                   878594 non-null  float64\n",
      " 60  AdRevenueD10                  878594 non-null  float64\n",
      " 61  AdRevenueD11                  878594 non-null  float64\n",
      " 62  AdRevenueD12                  878594 non-null  float64\n",
      " 63  AdRevenueD13                  878594 non-null  float64\n",
      " 64  AdRevenueD14                  878594 non-null  float64\n",
      " 65  AdRevenueD15                  878594 non-null  float64\n",
      " 66  IAPRevenueD0                  878594 non-null  float64\n",
      " 67  IAPRevenueD1                  878594 non-null  float64\n",
      " 68  IAPRevenueD2                  878594 non-null  float64\n",
      " 69  IAPRevenueD3                  878594 non-null  float64\n",
      " 70  IAPRevenueD4                  878594 non-null  float64\n",
      " 71  IAPRevenueD5                  878594 non-null  float64\n",
      " 72  IAPRevenueD6                  878594 non-null  float64\n",
      " 73  IAPRevenueD7                  878594 non-null  float64\n",
      " 74  IAPRevenueD8                  878594 non-null  float64\n",
      " 75  IAPRevenueD9                  878594 non-null  float64\n",
      " 76  IAPRevenueD10                 878594 non-null  float64\n",
      " 77  IAPRevenueD11                 878594 non-null  float64\n",
      " 78  IAPRevenueD12                 878594 non-null  float64\n",
      " 79  IAPRevenueD13                 878594 non-null  float64\n",
      " 80  IAPRevenueD14                 878594 non-null  float64\n",
      " 81  IAPRevenueD15                 878594 non-null  float64\n",
      " 82  TARGET                        878594 non-null  float64\n",
      " 83  open_year                     878594 non-null  int64  \n",
      " 84  open_month                    878594 non-null  int64  \n",
      " 85  open_day                      878594 non-null  int64  \n",
      " 86  micro_first_open_times        878594 non-null  int64  \n",
      " 87  local_micro_first_open_times  878594 non-null  int64  \n",
      "dtypes: bool(17), float64(44), int64(21), object(6)\n",
      "memory usage: 490.2+ MB\n",
      "None\n",
      "\n",
      "--------------------  The First 5 Data  --------------------\n",
      "               country platform device_category device_brand  \\\n",
      "0               Mexico  Android          mobile       Xiaomi   \n",
      "1                 Peru  Android          mobile      Samsung   \n",
      "2               Brazil  Android          mobile       Xiaomi   \n",
      "3   Dominican Republic      iOS          mobile        Apple   \n",
      "4              Ecuador  Android          mobile     Motorola   \n",
      "5             Colombia  Android          mobile       Xiaomi   \n",
      "6            Venezuela  Android          mobile      Samsung   \n",
      "7              Germany      iOS          mobile        Apple   \n",
      "8               France  Android          mobile        Honor   \n",
      "9               Turkey      iOS          mobile        Apple   \n",
      "10       United States      iOS          mobile        Apple   \n",
      "11             Germany  Android          mobile      Samsung   \n",
      "12             Germany      iOS          mobile        Apple   \n",
      "13              Brazil  Android          mobile     Motorola   \n",
      "14              Brazil  Android          mobile       Xiaomi   \n",
      "15               India  Android          mobile       Xiaomi   \n",
      "16           Argentina  Android          mobile     Motorola   \n",
      "17         South Korea  Android          mobile      Samsung   \n",
      "18             Germany      iOS          mobile        Apple   \n",
      "19              Brazil  Android          mobile     Motorola   \n",
      "\n",
      "                  device_model  has_ios_att_permission    ad_network  \\\n",
      "0                     Redmi A2                   False  unityads_int   \n",
      "1                   Galaxy A13                   False  applovin_int   \n",
      "2                     Redmi 12                   False  applovin_int   \n",
      "3            iPhone 11 Pro Max                   False           NaN   \n",
      "4                     Moto E22                   False  applovin_int   \n",
      "5                 Redmi Note 8                   False           NaN   \n",
      "6                Galaxy S20 FE                   False  applovin_int   \n",
      "7                    iPhone 11                    True  applovin_int   \n",
      "8                          X9b                   False  applovin_int   \n",
      "9                    iPhone 11                    True           NaN   \n",
      "10  iPhone SE (2nd generation)                    True  applovin_int   \n",
      "11                  Galaxy S23                   False  applovin_int   \n",
      "12           iPhone 14 Pro Max                   False  applovin_int   \n",
      "13                    Moto E13                   False  applovin_int   \n",
      "14              Redmi Note 10S                   False  applovin_int   \n",
      "15                 Redmi 12 5G                   False  applovin_int   \n",
      "16                    Moto E32                   False  applovin_int   \n",
      "17             Galaxy Z Flip 5                   False  applovin_int   \n",
      "18               iPhone 13 Pro                   False           NaN   \n",
      "19                 Moto G84 5G                   False           NaN   \n",
      "\n",
      "    first_prediction  RetentionD0  RetentionD1  ...  IAPRevenueD12  \\\n",
      "0           3.314099         True        False  ...            0.0   \n",
      "1           1.681524         True        False  ...            0.0   \n",
      "2          10.718750         True        False  ...            0.0   \n",
      "3           5.100000         True         True  ...            0.0   \n",
      "4           2.091409         True        False  ...            0.0   \n",
      "5           1.667307         True         True  ...            0.0   \n",
      "6           0.600000         True        False  ...            0.0   \n",
      "7          51.674668         True        False  ...            0.0   \n",
      "8          32.578755         True         True  ...            0.0   \n",
      "9                NaN         True         True  ...            0.0   \n",
      "10         63.000001         True        False  ...            0.0   \n",
      "11         35.503965         True         True  ...            0.0   \n",
      "12         63.000001         True        False  ...            0.0   \n",
      "13          4.833947         True        False  ...            0.0   \n",
      "14          4.449134         True         True  ...            0.0   \n",
      "15          0.600000         True        False  ...            0.0   \n",
      "16          4.059153         True        False  ...            0.0   \n",
      "17         98.626889         True        False  ...            0.0   \n",
      "18         63.000001         True        False  ...            0.0   \n",
      "19         53.161468         True         True  ...            0.0   \n",
      "\n",
      "    IAPRevenueD13  IAPRevenueD14  IAPRevenueD15    TARGET  open_year  \\\n",
      "0             0.0            0.0            0.0  0.000000       2024   \n",
      "1             0.0            0.0            0.0  0.018892       2024   \n",
      "2             0.0            0.0            0.0  0.000000       2024   \n",
      "3             0.0            0.0            0.0  0.046650       2024   \n",
      "4             0.0            0.0            0.0  0.014680       2024   \n",
      "5             0.0            0.0            0.0  0.000000       2024   \n",
      "6             0.0            0.0            0.0  0.000000       2024   \n",
      "7             0.0            0.0            0.0  0.483761       2024   \n",
      "8             0.0            0.0            0.0  0.019910       2024   \n",
      "9             0.0            0.0            0.0  0.000000       2024   \n",
      "10            0.0            0.0            0.0  0.303196       2024   \n",
      "11            0.0            0.0            0.0  0.000000       2024   \n",
      "12            0.0            0.0            0.0  1.265949       2024   \n",
      "13            0.0            0.0            0.0  0.004446       2024   \n",
      "14            0.0            0.0            0.0  0.079513       2024   \n",
      "15            0.0            0.0            0.0  0.044076       2024   \n",
      "16            0.0            0.0            0.0  0.000000       2024   \n",
      "17            0.0            0.0            0.0  0.019255       2024   \n",
      "18            0.0            0.0            0.0  0.000000       2024   \n",
      "19            0.0            0.0            0.0  0.046317       2024   \n",
      "\n",
      "    open_month  open_day  micro_first_open_times  local_micro_first_open_times  \n",
      "0            3         2                  895042                        295042  \n",
      "1            3        19                  539731                        539731  \n",
      "2            3        18                   43082                        243082  \n",
      "3            3         3                  862260                        462260  \n",
      "4            4        30                  477190                        477190  \n",
      "5            4        23                  887691                        887691  \n",
      "6            3        30                  156974                        756974  \n",
      "7            5         4                  801586                          1586  \n",
      "8            4         5                  340553                        540553  \n",
      "9            3        20                  214755                         14755  \n",
      "10           2         6                  810317                         10317  \n",
      "11           2        26                  669438                        269438  \n",
      "12           5         4                  839460                         39460  \n",
      "13           4        28                  470587                        670587  \n",
      "14           4        30                  962880                        562880  \n",
      "15           2         5                  971878                        771878  \n",
      "16           5        16                  834103                         34103  \n",
      "17           2        18                  116780                        516780  \n",
      "18           4         7                  449028                        649028  \n",
      "19           1         6                  875588                         75588  \n",
      "\n",
      "[20 rows x 88 columns]\n",
      "--------------------     Data Shape     --------------------\n",
      "(878594, 88)\n"
     ]
    }
   ],
   "source": [
    "#çalıştır\n",
    "def check_data(dataframe):\n",
    " print(20*\"-\" + \"Information\".center(20) + 20*\"-\")\n",
    " print(dataframe.info())\n",
    " print(\"\\n\" + 20*\"-\" + \"The First 5 Data\".center(20) + 20*\"-\")\n",
    " print(dataframe.head(20))\n",
    " print(20*\"-\" + \"Data Shape\".center(20) + 20*\"-\")\n",
    " print(dataframe.shape)\n",
    "\n",
    "check_data(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:19.042500Z",
     "start_time": "2024-09-12T14:07:18.997477Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The unique values:\n",
      "ID                  10000\n",
      "first_prediction     7751\n",
      "AdRevenueD0          4240\n",
      "AdRevenueD1          2941\n",
      "AdRevenueD2          2205\n",
      "                    ...  \n",
      "IAPRevenueD7            1\n",
      "IAPRevenueD5            1\n",
      "IAPRevenueD0            1\n",
      "RetentionD0             1\n",
      "IAPRevenueD15           1\n",
      "Length: 76, dtype: int64\n",
      "cat_cols: ['RetentionD0', 'RetentionD1', 'RetentionD2', 'RetentionD3', 'RetentionD4', 'RetentionD5', 'RetentionD6', 'RetentionD7', 'RetentionD8', 'RetentionD9', 'RetentionD10', 'RetentionD11', 'RetentionD12', 'RetentionD13', 'RetentionD14', 'RetentionD15', 'IAPRevenueD0', 'IAPRevenueD1', 'IAPRevenueD2', 'IAPRevenueD3', 'IAPRevenueD4', 'IAPRevenueD5', 'IAPRevenueD6', 'IAPRevenueD7', 'IAPRevenueD8', 'IAPRevenueD9', 'IAPRevenueD10', 'IAPRevenueD11', 'IAPRevenueD12', 'IAPRevenueD13', 'IAPRevenueD14', 'IAPRevenueD15']\n",
      "num_cols: ['ID', 'first_prediction', 'LevelAdvancedCountD0', 'LevelAdvancedCountD1', 'LevelAdvancedCountD2', 'LevelAdvancedCountD3', 'LevelAdvancedCountD4', 'LevelAdvancedCountD5', 'LevelAdvancedCountD6', 'LevelAdvancedCountD7', 'LevelAdvancedCountD8', 'LevelAdvancedCountD9', 'LevelAdvancedCountD10', 'LevelAdvancedCountD11', 'LevelAdvancedCountD12', 'LevelAdvancedCountD13', 'LevelAdvancedCountD14', 'LevelAdvancedCountD15', 'Level_1_Duration', 'Level_2_Duration', 'Level_3_Duration', 'Level_4_Duration', 'Level_5_Duration', 'Level_6_Duration', 'Level_7_Duration', 'Level_8_Duration', 'Level_9_Duration', 'Level_10_Duration', 'AdRevenueD0', 'AdRevenueD1', 'AdRevenueD2', 'AdRevenueD3', 'AdRevenueD4', 'AdRevenueD5', 'AdRevenueD6', 'AdRevenueD7', 'AdRevenueD8', 'AdRevenueD9', 'AdRevenueD10', 'AdRevenueD11', 'AdRevenueD12', 'AdRevenueD13', 'AdRevenueD14', 'AdRevenueD15']\n",
      "num_cols but cat: ['RetentionD0', 'RetentionD1', 'RetentionD2', 'RetentionD3', 'RetentionD4', 'RetentionD5', 'RetentionD6', 'RetentionD7', 'RetentionD8', 'RetentionD9', 'RetentionD10', 'RetentionD11', 'RetentionD12', 'RetentionD13', 'RetentionD14', 'RetentionD15', 'IAPRevenueD0', 'IAPRevenueD1', 'IAPRevenueD2', 'IAPRevenueD3', 'IAPRevenueD4', 'IAPRevenueD5', 'IAPRevenueD6', 'IAPRevenueD7', 'IAPRevenueD8', 'IAPRevenueD9', 'IAPRevenueD10', 'IAPRevenueD11', 'IAPRevenueD12', 'IAPRevenueD13', 'IAPRevenueD14', 'IAPRevenueD15']\n",
      "cat_but_car: []\n",
      "cat_but_not_car: ['RetentionD0', 'RetentionD1', 'RetentionD2', 'RetentionD3', 'RetentionD4', 'RetentionD5', 'RetentionD6', 'RetentionD7', 'RetentionD8', 'RetentionD9', 'RetentionD10', 'RetentionD11', 'RetentionD12', 'RetentionD13', 'RetentionD14', 'RetentionD15', 'IAPRevenueD0', 'IAPRevenueD1', 'IAPRevenueD2', 'IAPRevenueD3', 'IAPRevenueD4', 'IAPRevenueD5', 'IAPRevenueD6', 'IAPRevenueD7', 'IAPRevenueD8', 'IAPRevenueD9', 'IAPRevenueD10', 'IAPRevenueD11', 'IAPRevenueD12', 'IAPRevenueD13', 'IAPRevenueD14', 'IAPRevenueD15']\n",
      "\n",
      "\n",
      "The unique values:\n",
      "micro_first_open_times          9957\n",
      "local_micro_first_open_times    9944\n",
      "device_model                    1018\n",
      "country                          121\n",
      "device_brand                      62\n",
      "open_day                          31\n",
      "ad_network                         5\n",
      "open_month                         5\n",
      "platform                           2\n",
      "device_category                    2\n",
      "has_ios_att_permission             2\n",
      "open_year                          1\n",
      "dtype: int64\n",
      "cat_cols: ['platform', 'device_category', 'ad_network', 'has_ios_att_permission', 'open_year', 'open_month']\n",
      "num_cols: ['open_day', 'micro_first_open_times', 'local_micro_first_open_times']\n",
      "num_cols but cat: ['has_ios_att_permission', 'open_year', 'open_month']\n",
      "cat_but_car: ['country', 'device_brand', 'device_model']\n",
      "cat_but_not_car: ['platform', 'device_category', 'ad_network', 'has_ios_att_permission', 'open_year', 'open_month']\n"
     ]
    }
   ],
   "source": [
    "def grab_col_names(dataframe, cat_th, car_th):\n",
    "    \"\"\"\n",
    "    Grabs the column names according to data type and unique value counts.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: pandas DataFrame to evaluate.\n",
    "    - cat_th: Threshold for the number of unique values to consider a numerical column as categorical.\n",
    "    - car_th: Threshold for the number of unique values to consider a categorical column as cardinal.\n",
    "\n",
    "    Returns:\n",
    "    - cat_cols: List of categorical column names.\n",
    "    - cat_but_car: List of categorical but cardinal column names.\n",
    "    - num_but_cat: List of numerical columns considered as categorical due to low number of unique values.\n",
    "    - num_cols: List of numerical column names.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # cat_cols, cat_but_car\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
    "                   dataframe[col].dtypes != \"O\"]\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
    "                   dataframe[col].dtypes == \"O\"]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    # num_cols\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "    # Categorical columns that are not considered cardinal\n",
    "    cat_but_not_car = [col for col in cat_cols if col not in cat_but_car]\n",
    "    \n",
    "\n",
    "# Display unique value counts for all columns\n",
    "    uniquevalue = dataframe.nunique().sort_values(ascending=False)\n",
    "    print(f\"The unique values:\\n{uniquevalue}\")\n",
    "    \n",
    "    # Output column lists\n",
    "    print(f\"cat_cols: {cat_cols}\")\n",
    "    print(f'num_cols: {num_cols}')\n",
    "    print(f'num_cols but cat: {num_but_cat}')\n",
    "    print(f'cat_but_car: {cat_but_car}')\n",
    "    print(f'cat_but_not_car: {cat_but_not_car}')\n",
    "    \n",
    "    # Return the column lists\n",
    "    return cat_cols, cat_but_car, num_but_cat, num_cols, cat_but_not_car\n",
    "\n",
    "# Test the function with both train and test datasets\n",
    "\n",
    "print(\"\\n\")\n",
    "cat_cols_testFeatures, cat_but_car_testFeatures, num_but_cat_testFeatures, num_cols_testFeatures, cat_but_not_car_testFeatures = grab_col_names(testFeaturescopy, 10, 30)\n",
    "print(\"\\n\")\n",
    "\n",
    "cat_cols_testUsers, cat_but_car_testUsers, num_but_cat_testUsers, num_cols_testUsers, cat_but_not_car_testUsers = grab_col_names(testUserscopy, 10, 30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:20.034268Z",
     "start_time": "2024-09-12T14:07:19.043492Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The null values percent data:\n",
      "\n",
      "    Level_10_Duration        40.42\n",
      "Level_9_Duration         36.32\n",
      "Level_8_Duration         34.35\n",
      "Level_7_Duration         30.92\n",
      "Level_6_Duration         26.24\n",
      "                         ...  \n",
      "LevelAdvancedCountD10     0.00\n",
      "LevelAdvancedCountD11     0.00\n",
      "LevelAdvancedCountD12     0.00\n",
      "LevelAdvancedCountD13     0.00\n",
      "IAPRevenueD15             0.00\n",
      "Length: 76, dtype: float64\n",
      "          \n",
      "          \n",
      "Columns with null values greater than 45%: [] \n",
      "\n",
      "Columns with null values is 0% : ['ID', 'RetentionD0', 'RetentionD1', 'RetentionD2', 'RetentionD3', 'RetentionD4', 'RetentionD5', 'RetentionD6', 'RetentionD7', 'RetentionD8', 'RetentionD9', 'RetentionD10', 'RetentionD11', 'RetentionD12', 'RetentionD13', 'RetentionD14', 'RetentionD15', 'LevelAdvancedCountD0', 'LevelAdvancedCountD1', 'LevelAdvancedCountD2', 'LevelAdvancedCountD3', 'LevelAdvancedCountD4', 'LevelAdvancedCountD5', 'LevelAdvancedCountD6', 'LevelAdvancedCountD7', 'LevelAdvancedCountD8', 'LevelAdvancedCountD9', 'LevelAdvancedCountD10', 'LevelAdvancedCountD11', 'LevelAdvancedCountD12', 'LevelAdvancedCountD13', 'LevelAdvancedCountD14', 'LevelAdvancedCountD15', 'AdRevenueD0', 'AdRevenueD1', 'AdRevenueD2', 'AdRevenueD3', 'AdRevenueD4', 'AdRevenueD5', 'AdRevenueD6', 'AdRevenueD7', 'AdRevenueD8', 'AdRevenueD9', 'AdRevenueD10', 'AdRevenueD11', 'AdRevenueD12', 'AdRevenueD13', 'AdRevenueD14', 'AdRevenueD15', 'IAPRevenueD0', 'IAPRevenueD1', 'IAPRevenueD2', 'IAPRevenueD3', 'IAPRevenueD4', 'IAPRevenueD5', 'IAPRevenueD6', 'IAPRevenueD7', 'IAPRevenueD8', 'IAPRevenueD9', 'IAPRevenueD10', 'IAPRevenueD11', 'IAPRevenueD12', 'IAPRevenueD13', 'IAPRevenueD14', 'IAPRevenueD15']\n",
      "\n",
      "Columns with null values between 0 - 45%: ['first_prediction', 'Level_1_Duration', 'Level_2_Duration', 'Level_3_Duration', 'Level_4_Duration', 'Level_5_Duration', 'Level_6_Duration', 'Level_7_Duration', 'Level_8_Duration', 'Level_9_Duration', 'Level_10_Duration'] \n",
      "\n",
      "\n",
      "The null values percent data:\n",
      "\n",
      "    Level_10_Duration               40.489645\n",
      "Level_9_Duration                36.210029\n",
      "ad_network                      35.270688\n",
      "Level_8_Duration                34.222082\n",
      "Level_7_Duration                30.604715\n",
      "                                  ...    \n",
      "LevelAdvancedCountD14            0.000000\n",
      "LevelAdvancedCountD13            0.000000\n",
      "LevelAdvancedCountD12            0.000000\n",
      "LevelAdvancedCountD11            0.000000\n",
      "local_micro_first_open_times     0.000000\n",
      "Length: 87, dtype: float64\n",
      "          \n",
      "          \n",
      "Columns with null values greater than 45%: [] \n",
      "\n",
      "Columns with null values is 0% : ['platform', 'device_category', 'device_model', 'has_ios_att_permission', 'RetentionD0', 'RetentionD1', 'RetentionD2', 'RetentionD3', 'RetentionD4', 'RetentionD5', 'RetentionD6', 'RetentionD7', 'RetentionD8', 'RetentionD9', 'RetentionD10', 'RetentionD11', 'RetentionD12', 'RetentionD13', 'RetentionD14', 'RetentionD15', 'LevelAdvancedCountD0', 'LevelAdvancedCountD1', 'LevelAdvancedCountD2', 'LevelAdvancedCountD3', 'LevelAdvancedCountD4', 'LevelAdvancedCountD5', 'LevelAdvancedCountD6', 'LevelAdvancedCountD7', 'LevelAdvancedCountD8', 'LevelAdvancedCountD9', 'LevelAdvancedCountD10', 'LevelAdvancedCountD11', 'LevelAdvancedCountD12', 'LevelAdvancedCountD13', 'LevelAdvancedCountD14', 'LevelAdvancedCountD15', 'AdRevenueD0', 'AdRevenueD1', 'AdRevenueD2', 'AdRevenueD3', 'AdRevenueD4', 'AdRevenueD5', 'AdRevenueD6', 'AdRevenueD7', 'AdRevenueD8', 'AdRevenueD9', 'AdRevenueD10', 'AdRevenueD11', 'AdRevenueD12', 'AdRevenueD13', 'AdRevenueD14', 'AdRevenueD15', 'IAPRevenueD0', 'IAPRevenueD1', 'IAPRevenueD2', 'IAPRevenueD3', 'IAPRevenueD4', 'IAPRevenueD5', 'IAPRevenueD6', 'IAPRevenueD7', 'IAPRevenueD8', 'IAPRevenueD9', 'IAPRevenueD10', 'IAPRevenueD11', 'IAPRevenueD12', 'IAPRevenueD13', 'IAPRevenueD14', 'IAPRevenueD15', 'open_year', 'open_month', 'open_day', 'micro_first_open_times', 'local_micro_first_open_times']\n",
      "\n",
      "Columns with null values between 0 - 45%: ['country', 'device_brand', 'ad_network', 'first_prediction', 'Level_1_Duration', 'Level_2_Duration', 'Level_3_Duration', 'Level_4_Duration', 'Level_5_Duration', 'Level_6_Duration', 'Level_7_Duration', 'Level_8_Duration', 'Level_9_Duration', 'Level_10_Duration'] \n",
      "\n",
      "\n",
      "\n",
      "The null values percent data:\n",
      "\n",
      "    ad_network                      35.26\n",
      "device_brand                     0.62\n",
      "country                          0.00\n",
      "platform                         0.00\n",
      "device_category                  0.00\n",
      "device_model                     0.00\n",
      "has_ios_att_permission           0.00\n",
      "open_year                        0.00\n",
      "open_month                       0.00\n",
      "open_day                         0.00\n",
      "micro_first_open_times           0.00\n",
      "local_micro_first_open_times     0.00\n",
      "dtype: float64\n",
      "          \n",
      "          \n",
      "Columns with null values greater than 45%: [] \n",
      "\n",
      "Columns with null values is 0% : ['country', 'platform', 'device_category', 'device_model', 'has_ios_att_permission', 'open_year', 'open_month', 'open_day', 'micro_first_open_times', 'local_micro_first_open_times']\n",
      "\n",
      "Columns with null values between 0 - 45%: ['device_brand', 'ad_network'] \n",
      "\n",
      "\n",
      "\n",
      "The null values percent data:\n",
      "\n",
      "    ad_network                    34.97\n",
      "device_brand                   0.69\n",
      "country                        0.01\n",
      "first_open_date                0.00\n",
      "first_open_timestamp           0.00\n",
      "local_first_open_timestamp     0.00\n",
      "platform                       0.00\n",
      "device_category                0.00\n",
      "device_model                   0.00\n",
      "has_ios_att_permission         0.00\n",
      "dtype: float64\n",
      "          \n",
      "          \n",
      "Columns with null values greater than 45%: [] \n",
      "\n",
      "Columns with null values is 0% : ['first_open_date', 'first_open_timestamp', 'local_first_open_timestamp', 'platform', 'device_category', 'device_model', 'has_ios_att_permission']\n",
      "\n",
      "Columns with null values between 0 - 45%: ['country', 'device_brand', 'ad_network'] \n"
     ]
    }
   ],
   "source": [
    "#çalıştır\n",
    "def checknull(data,percentvalue):\n",
    "    \n",
    "    upperPercentValueColumnlist=[col for col in data.columns if data[col].isnull().mean()*100>percentvalue]\n",
    "    #boş değeri %15'ten fazla olan sütunlar\n",
    "    betweenPercentValueColumnlist=[col for col in data.columns if data[col].isnull().mean()*100<percentvalue and data[col].isnull().mean()*100>0]\n",
    "    #boş değeri %0-15 arasında olan sütunlar\n",
    "    zeroPercentnullValueColumnlist=[col for col in data.columns if data[col].isnull().mean()==0]\n",
    "    # boş değeri 0 olan değerler\n",
    "    null_percent=(data.isnull().mean()*100).sort_values(ascending=False)\n",
    "    \n",
    "    print(f\"\"\"\n",
    "The null values percent data:\n",
    "\n",
    "    {null_percent}\n",
    "          \n",
    "          \n",
    "Columns with null values greater than {percentvalue}%: {upperPercentValueColumnlist} \n",
    "\n",
    "Columns with null values is 0% : {zeroPercentnullValueColumnlist}\n",
    "\n",
    "Columns with null values between 0 - {percentvalue}%: {betweenPercentValueColumnlist} \n",
    "\n",
    "\"\"\")\n",
    "    return upperPercentValueColumnlist,betweenPercentValueColumnlist,zeroPercentnullValueColumnlist,null_percent\n",
    "\n",
    "upperPercentValueColumnlistTrainFeatures,betweenPercentValueColumnlistTrainFeatures,zeroPercentnullValueColumnlistTrainFeatures,null_percentTrainFeatures=checknull(trainFeaturescopy,45)\n",
    "upperPercentValueColumnlistTestFeatures,betweenPercentValueColumnlistTestFeatures,zeroPercentnullValueColumnlistTestFeatures,null_percentTestFeatures=checknull(test,45)\n",
    "upperPercentValueColumnlistTestUsers,betweenPercentValueColumnlistTestUsers,zeroPercentnullValueColumnlistTestUsers,null_percentTestUsers=checknull(testUserscopy,45)\n",
    "upperPercentValueColumnlistTrainUsers,betweenPercentValueColumnlistTrainUsers,zeroPercentnullValueColumnlistTrainUsers,null_percentTrainUsers=checknull(trainUserscopy,45)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def gra(dataframe, cat_th, car_th):\n",
    "    \"\"\"\n",
    "    Parameters (for null values):\n",
    "    dataframe (pd.DataFrame): DataFrame to analyze.\n",
    "    cat_th (int): Threshold for numeric columns to be treated as categorical.\n",
    "    car_th (int): Threshold for categorical columns to be considered cardinal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Columns with null values that are categorical\n",
    "    null_value_cat_cols = [col for col in zeroPercentnullValueColumnlistTestFeatures if dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    # Numeric columns with null values but few unique values (treated as categorical)\n",
    "    null_value_num_but_cat = [\n",
    "        col for col in zeroPercentnullValueColumnlistTestFeatures if dataframe[col].nunique() < cat_th and dataframe[col].dtypes != \"O\"]\n",
    "\n",
    "    # Combine categorical and numeric-as-categorical columns\n",
    "    null_value_cat_cols += null_value_num_but_cat\n",
    "\n",
    "    # Categorical columns with many unique values (cardinal)\n",
    "    null_value_cat_but_car = [\n",
    "        col for col in zeroPercentnullValueColumnlistTestFeatures if dataframe[col].nunique() > car_th and dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    null_num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    \n",
    "    null_num_cols = [col for col in null_num_cols if col not in null_value_cat_cols]\n",
    "\n",
    "    # Print number of unique values\n",
    "    print(f\"The unique values:\\n {dataframe[zeroPercentnullValueColumnlistTestFeatures].nunique().sort_values(ascending=False)}\")\n",
    "\n",
    "    # Print categorized columns\n",
    "    print(f\"Categorical columns with nulls: {null_value_cat_cols}\")\n",
    "    print(f'Cardinal categorical columns with nulls: {null_value_cat_but_car}')\n",
    "    print(f'Numeric columns with nulls (treated as categorical): {null_value_num_but_cat}')\n",
    "\n",
    "    return null_value_cat_cols, null_value_cat_but_car, null_value_num_but_cat, null_num_cols\n",
    "\n",
    "# Example usage\n",
    "null_value_cat_cols_user, null_value_num_but_cat_user, null_value_cat_but_car_user,null_num_cols = grab_col_names(test, 10, 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# IAPRevenue için benzer sütunlar oluşturma\n",
    "train[\"IAPRevenueTotal2\"] = train[\"IAPRevenueD0\"] + train[\"IAPRevenueD1\"]\n",
    "train[\"IAPRevenueTotal4\"] = train[\"IAPRevenueD2\"] + train[\"IAPRevenueD3\"]\n",
    "train[\"IAPRevenueTotal6\"] = train[\"IAPRevenueD4\"] + train[\"IAPRevenueD5\"]\n",
    "train[\"IAPRevenueTotal8\"] = train[\"IAPRevenueD6\"] + train[\"IAPRevenueD7\"]\n",
    "train[\"IAPRevenueTotal10\"] = train[\"IAPRevenueD8\"] + train[\"IAPRevenueD9\"]\n",
    "train[\"IAPRevenueTotal12\"] = train[\"IAPRevenueD10\"] + train[\"IAPRevenueD11\"]\n",
    "train[\"IAPRevenueTotal14\"] = train[\"IAPRevenueD12\"] + train[\"IAPRevenueD13\"]\n",
    "train[\"IAPRevenueTotal16\"] = train[\"IAPRevenueD14\"] + train[\"IAPRevenueD15\"]\n",
    "\n",
    "\n",
    "# LevelAdvancedCountTotal\n",
    "train[\"LevelAdvancedCountTotal2\"] = train[\"LevelAdvancedCountD0\"] + train[\"LevelAdvancedCountD1\"]\n",
    "train[\"LevelAdvancedCountTotal4\"] = train[\"LevelAdvancedCountD2\"] + train[\"LevelAdvancedCountD3\"]\n",
    "train[\"LevelAdvancedCountTotal6\"] = train[\"LevelAdvancedCountD4\"] + train[\"LevelAdvancedCountD5\"]\n",
    "train[\"LevelAdvancedCountTotal8\"] = train[\"LevelAdvancedCountD6\"] + train[\"LevelAdvancedCountD7\"]\n",
    "train[\"LevelAdvancedCountTotal10\"] = train[\"LevelAdvancedCountD8\"] + train[\"LevelAdvancedCountD9\"]\n",
    "train[\"LevelAdvancedCountTotal12\"] = train[\"LevelAdvancedCountD10\"] + train[\"LevelAdvancedCountD11\"]\n",
    "train[\"LevelAdvancedCountTotal14\"] = train[\"LevelAdvancedCountD12\"] + train[\"LevelAdvancedCountD13\"]\n",
    "train[\"LevelAdvancedCountTotal16\"] = train[\"LevelAdvancedCountD14\"] + train[\"LevelAdvancedCountD15\"]\n",
    "\n",
    "# Level Duration\n",
    "train[\"LevelDurationTotal2\"] = train[\"Level_1_Duration\"] + train[\"Level_2_Duration\"]\n",
    "train[\"LevelDurationTotal4\"] = train[\"Level_3_Duration\"] + train[\"Level_4_Duration\"]\n",
    "train[\"LevelDurationTotal6\"] = train[\"Level_5_Duration\"] + train[\"Level_6_Duration\"]\n",
    "train[\"LevelDurationTotal8\"] = train[\"Level_7_Duration\"] + train[\"Level_8_Duration\"]\n",
    "train[\"LevelDurationTotal10\"] = train[\"Level_9_Duration\"] + train[\"Level_10_Duration\"]\n",
    "\n",
    "# AdRevenue\n",
    "train[\"AdRevenueTotal2\"] = train[\"AdRevenueD0\"] + train[\"AdRevenueD1\"]\n",
    "train[\"AdRevenueTotal4\"] = train[\"AdRevenueD2\"] + train[\"AdRevenueD3\"]\n",
    "train[\"AdRevenueTotal6\"] = train[\"AdRevenueD4\"] + train[\"AdRevenueD5\"]\n",
    "train[\"AdRevenueTotal8\"] = train[\"AdRevenueD6\"] + train[\"AdRevenueD7\"]\n",
    "train[\"AdRevenueTotal10\"] = train[\"AdRevenueD8\"] + train[\"AdRevenueD9\"]\n",
    "train[\"AdRevenueTotal12\"] = train[\"AdRevenueD10\"] + train[\"AdRevenueD11\"]\n",
    "train[\"AdRevenueTotal14\"] = train[\"AdRevenueD12\"] + train[\"AdRevenueD13\"]\n",
    "train[\"AdRevenueTotal16\"] = train[\"AdRevenueD14\"] + train[\"AdRevenueD15\"]\n",
    "\n",
    "\n",
    "# Retention için benzer sütunlar oluşturma (train seti)\n",
    "train[\"RetentionTotal2\"] = train[\"RetentionD0\"] + train[\"RetentionD1\"]\n",
    "train[\"RetentionTotal4\"] = train[\"RetentionD2\"] + train[\"RetentionD3\"]\n",
    "train[\"RetentionTotal6\"] = train[\"RetentionD4\"] + train[\"RetentionD5\"]\n",
    "train[\"RetentionTotal8\"] = train[\"RetentionD6\"] + train[\"RetentionD7\"]\n",
    "train[\"RetentionTotal10\"] = train[\"RetentionD8\"] + train[\"RetentionD9\"]\n",
    "train[\"RetentionTotal12\"] = train[\"RetentionD10\"] + train[\"RetentionD11\"]\n",
    "train[\"RetentionTotal14\"] = train[\"RetentionD12\"] + train[\"RetentionD13\"]\n",
    "train[\"RetentionTotal16\"] = train[\"RetentionD14\"] + train[\"RetentionD15\"]\n",
    "\n",
    "\n",
    "\n",
    "# LevelAdvancedCountTotal\n",
    "test[\"LevelAdvancedCountTotal2\"] = test[\"LevelAdvancedCountD0\"] + test[\"LevelAdvancedCountD1\"]\n",
    "test[\"LevelAdvancedCountTotal4\"] = test[\"LevelAdvancedCountD2\"] + test[\"LevelAdvancedCountD3\"]\n",
    "test[\"LevelAdvancedCountTotal6\"] = test[\"LevelAdvancedCountD4\"] + test[\"LevelAdvancedCountD5\"]\n",
    "test[\"LevelAdvancedCountTotal8\"] = test[\"LevelAdvancedCountD6\"] + test[\"LevelAdvancedCountD7\"]\n",
    "test[\"LevelAdvancedCountTotal10\"] = test[\"LevelAdvancedCountD8\"] + test[\"LevelAdvancedCountD9\"]\n",
    "test[\"LevelAdvancedCountTotal12\"] = test[\"LevelAdvancedCountD10\"] + test[\"LevelAdvancedCountD11\"]\n",
    "test[\"LevelAdvancedCountTotal14\"] = test[\"LevelAdvancedCountD12\"] + test[\"LevelAdvancedCountD13\"]\n",
    "test[\"LevelAdvancedCountTotal16\"] = test[\"LevelAdvancedCountD14\"] + test[\"LevelAdvancedCountD15\"]\n",
    "\n",
    "# Level Duration\n",
    "test[\"LevelDurationTotal2\"] = test[\"Level_1_Duration\"] + test[\"Level_2_Duration\"]\n",
    "test[\"LevelDurationTotal4\"] = test[\"Level_3_Duration\"] + test[\"Level_4_Duration\"]\n",
    "test[\"LevelDurationTotal6\"] = test[\"Level_5_Duration\"] + test[\"Level_6_Duration\"]\n",
    "test[\"LevelDurationTotal8\"] = test[\"Level_7_Duration\"] + test[\"Level_8_Duration\"]\n",
    "test[\"LevelDurationTotal10\"] = test[\"Level_9_Duration\"] + test[\"Level_10_Duration\"]\n",
    "\n",
    "# AdRevenue\n",
    "test[\"AdRevenueTotal2\"] = test[\"AdRevenueD0\"] + test[\"AdRevenueD1\"]\n",
    "test[\"AdRevenueTotal4\"] = test[\"AdRevenueD2\"] + test[\"AdRevenueD3\"]\n",
    "test[\"AdRevenueTotal6\"] = test[\"AdRevenueD4\"] + test[\"AdRevenueD5\"]\n",
    "test[\"AdRevenueTotal8\"] = test[\"AdRevenueD6\"] + test[\"AdRevenueD7\"]\n",
    "test[\"AdRevenueTotal10\"] = test[\"AdRevenueD8\"] + test[\"AdRevenueD9\"]\n",
    "test[\"AdRevenueTotal12\"] = test[\"AdRevenueD10\"] + test[\"AdRevenueD11\"]\n",
    "test[\"AdRevenueTotal14\"] = test[\"AdRevenueD12\"] + test[\"AdRevenueD13\"]\n",
    "test[\"AdRevenueTotal16\"] = test[\"AdRevenueD14\"] + test[\"AdRevenueD15\"]\n",
    "\n",
    "\n",
    "# IAPRevenue için benzer sütunlar oluşturma (test seti)\n",
    "test[\"IAPRevenueTotal2\"] = test[\"IAPRevenueD0\"] + test[\"IAPRevenueD1\"]\n",
    "test[\"IAPRevenueTotal4\"] = test[\"IAPRevenueD2\"] + test[\"IAPRevenueD3\"]\n",
    "test[\"IAPRevenueTotal6\"] = test[\"IAPRevenueD4\"] + test[\"IAPRevenueD5\"]\n",
    "test[\"IAPRevenueTotal8\"] = test[\"IAPRevenueD6\"] + test[\"IAPRevenueD7\"]\n",
    "test[\"IAPRevenueTotal10\"] = test[\"IAPRevenueD8\"] + test[\"IAPRevenueD9\"]\n",
    "test[\"IAPRevenueTotal12\"] = test[\"IAPRevenueD10\"] + test[\"IAPRevenueD11\"]\n",
    "test[\"IAPRevenueTotal14\"] = test[\"IAPRevenueD12\"] + test[\"IAPRevenueD13\"]\n",
    "test[\"IAPRevenueTotal16\"] = test[\"IAPRevenueD14\"] + test[\"IAPRevenueD15\"]\n",
    "\n",
    "\n",
    "# Retention için benzer sütunlar oluşturma (test seti)\n",
    "test[\"RetentionTotal2\"] = test[\"RetentionD0\"] + test[\"RetentionD1\"]\n",
    "test[\"RetentionTotal4\"] = test[\"RetentionD2\"] + test[\"RetentionD3\"]\n",
    "test[\"RetentionTotal6\"] = test[\"RetentionD4\"] + test[\"RetentionD5\"]\n",
    "test[\"RetentionTotal8\"] = test[\"RetentionD6\"] + test[\"RetentionD7\"]\n",
    "test[\"RetentionTotal10\"] = test[\"RetentionD8\"] + test[\"RetentionD9\"]\n",
    "test[\"RetentionTotal12\"] = test[\"RetentionD10\"] + test[\"RetentionD11\"]\n",
    "test[\"RetentionTotal14\"] = test[\"RetentionD12\"] + test[\"RetentionD13\"]\n",
    "test[\"RetentionTotal16\"] = test[\"RetentionD14\"] + test[\"RetentionD15\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#çalıştır\n",
    "\n",
    "def grab_col_names(dataframe, cat_th, car_th, column_list):\n",
    "    \"\"\"\n",
    "    Grabs the column names according to data type and unique value counts from a specific column list.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: pandas DataFrame to evaluate.\n",
    "    - cat_th: Threshold for the number of unique values to consider a numerical column as categorical.\n",
    "    - car_th: Threshold for the number of unique values to consider a categorical column as cardinal.\n",
    "    - column_list: List of columns to evaluate instead of all columns.\n",
    "\n",
    "    Returns:\n",
    "    - cat_cols: List of categorical column names.\n",
    "    - cat_but_car: List of categorical but cardinal column names.\n",
    "    - num_but_cat: List of numerical columns considered as categorical due to low number of unique values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Categorical columns within the specific column list\n",
    "    string_categoric_cols = [col for col in column_list if dataframe[col].dtype == \"O\" and dataframe[col].nunique() < cat_th]\n",
    "    \n",
    "    # Numerical but categorical columns within the specific column list\n",
    "    numeric_cols = [col for col in column_list if dataframe[col].nunique() > cat_th and dataframe[col].dtype != \"O\"]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Categorical but cardinal columns within the specific column list\n",
    "    cardinal_col = [col for col in column_list if dataframe[col].nunique() > car_th and dataframe[col].dtype == \"O\"]\n",
    "\n",
    " \n",
    "    \n",
    "    # Print unique value counts for the specified columns\n",
    "    print(f\"The unique values:\\n {dataframe[column_list].nunique().sort_values(ascending=False)}\")\n",
    "    \n",
    "    # Output column lists\n",
    "    print(f\"null column string categoric columns: {string_categoric_cols}\")\n",
    "    print(f'null column numeric: {numeric_cols}')\n",
    "    print(f'null column cardinal columns: {cardinal_col}')\n",
    "    \n",
    "\n",
    "    \n",
    "    # Return the column lists\n",
    "    return string_categoric_cols, cardinal_col, numeric_cols,\n",
    "\n",
    "# Example usage with a specific column list for columns with missing values\n",
    "\n",
    "stringtrainFeature_categoric_cols, cardinaltrainFeature_col, numerictrainFeature_cols = grab_col_names(trainFeaturescopy, 10, 20, betweenPercentValueColumnlistTrainFeatures)\n",
    "\n",
    "stringtestFeature_categoric_cols, cardinaltestFeature_col, numerictestFeature_cols = grab_col_names(testUsers, 10, 20, betweenPercentValueColumnlistTestFeatures)\n",
    "\n",
    "stringtrainUser_categoric_cols, cardinaltrainUser_col, numerictrainUser_cols = grab_col_names(trainUserscopy, 10, 20,betweenPercentValueColumnlistTrainUsers)\n",
    "stringtestUser_categoric_cols, cardinaltestUser_col, numerictestUser_cols = grab_col_names(testUserscopy, 10, 20, betweenPercentValueColumnlistTestUsers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def handle_outliers(dataframe, col_name, q1=0.25, q3=0.75, replace=True):\n",
    "    # Aykırı değer sınırlarını hesapla\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "\n",
    "    # Aykırı değer kontrolü yap\n",
    "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
    "        print(f\"Aykırı değer bulundu: {col_name}\")\n",
    "        if replace:\n",
    "            # Aykırı değerleri sınır değerlerle değiştir\n",
    "            dataframe.loc[dataframe[col_name] > up_limit, col_name] = quartile3\n",
    "            dataframe.loc[dataframe[col_name] < low_limit, col_name] = quartile1\n",
    "            print(f\"Aykırı değerler {col_name} sütununda sınırlarla değiştirildi.\")\n",
    "    else:\n",
    "        print(f\"Aykırı değer yok: {col_name}\")\n",
    "\n",
    "    return dataframe\n",
    "liste=num_cols_testUsers+num_cols_testFeatures\n",
    "liste.remove(\"ID\")\n",
    "\n",
    "for col in liste:\n",
    "    train = handle_outliers(train, col)\n",
    "    test = handle_outliers(test, col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# IAPRevenue için benzer sütunlar oluşturma\n",
    "train[\"IAPRevenueTotal2\"] = train[\"IAPRevenueD0\"] + train[\"IAPRevenueD1\"]\n",
    "train[\"IAPRevenueTotal4\"] = train[\"IAPRevenueD2\"] + train[\"IAPRevenueD3\"]\n",
    "train[\"IAPRevenueTotal6\"] = train[\"IAPRevenueD4\"] + train[\"IAPRevenueD5\"]\n",
    "train[\"IAPRevenueTotal8\"] = train[\"IAPRevenueD6\"] + train[\"IAPRevenueD7\"]\n",
    "train[\"IAPRevenueTotal10\"] = train[\"IAPRevenueD8\"] + train[\"IAPRevenueD9\"]\n",
    "train[\"IAPRevenueTotal12\"] = train[\"IAPRevenueD10\"] + train[\"IAPRevenueD11\"]\n",
    "train[\"IAPRevenueTotal14\"] = train[\"IAPRevenueD12\"] + train[\"IAPRevenueD13\"]\n",
    "train[\"IAPRevenueTotal16\"] = train[\"IAPRevenueD14\"] + train[\"IAPRevenueD15\"]\n",
    "\n",
    "\n",
    "# LevelAdvancedCountTotal\n",
    "train[\"LevelAdvancedCountTotal2\"] = train[\"LevelAdvancedCountD0\"] + train[\"LevelAdvancedCountD1\"]\n",
    "train[\"LevelAdvancedCountTotal4\"] = train[\"LevelAdvancedCountD2\"] + train[\"LevelAdvancedCountD3\"]\n",
    "train[\"LevelAdvancedCountTotal6\"] = train[\"LevelAdvancedCountD4\"] + train[\"LevelAdvancedCountD5\"]\n",
    "train[\"LevelAdvancedCountTotal8\"] = train[\"LevelAdvancedCountD6\"] + train[\"LevelAdvancedCountD7\"]\n",
    "train[\"LevelAdvancedCountTotal10\"] = train[\"LevelAdvancedCountD8\"] + train[\"LevelAdvancedCountD9\"]\n",
    "train[\"LevelAdvancedCountTotal12\"] = train[\"LevelAdvancedCountD10\"] + train[\"LevelAdvancedCountD11\"]\n",
    "train[\"LevelAdvancedCountTotal14\"] = train[\"LevelAdvancedCountD12\"] + train[\"LevelAdvancedCountD13\"]\n",
    "train[\"LevelAdvancedCountTotal16\"] = train[\"LevelAdvancedCountD14\"] + train[\"LevelAdvancedCountD15\"]\n",
    "\n",
    "# Level Duration\n",
    "train[\"LevelDurationTotal2\"] = train[\"Level_1_Duration\"] + train[\"Level_2_Duration\"]\n",
    "train[\"LevelDurationTotal4\"] = train[\"Level_3_Duration\"] + train[\"Level_4_Duration\"]\n",
    "train[\"LevelDurationTotal6\"] = train[\"Level_5_Duration\"] + train[\"Level_6_Duration\"]\n",
    "train[\"LevelDurationTotal8\"] = train[\"Level_7_Duration\"] + train[\"Level_8_Duration\"]\n",
    "train[\"LevelDurationTotal10\"] = train[\"Level_9_Duration\"] + train[\"Level_10_Duration\"]\n",
    "\n",
    "# AdRevenue\n",
    "train[\"AdRevenueTotal2\"] = train[\"AdRevenueD0\"] + train[\"AdRevenueD1\"]\n",
    "train[\"AdRevenueTotal4\"] = train[\"AdRevenueD2\"] + train[\"AdRevenueD3\"]\n",
    "train[\"AdRevenueTotal6\"] = train[\"AdRevenueD4\"] + train[\"AdRevenueD5\"]\n",
    "train[\"AdRevenueTotal8\"] = train[\"AdRevenueD6\"] + train[\"AdRevenueD7\"]\n",
    "train[\"AdRevenueTotal10\"] = train[\"AdRevenueD8\"] + train[\"AdRevenueD9\"]\n",
    "train[\"AdRevenueTotal12\"] = train[\"AdRevenueD10\"] + train[\"AdRevenueD11\"]\n",
    "train[\"AdRevenueTotal14\"] = train[\"AdRevenueD12\"] + train[\"AdRevenueD13\"]\n",
    "train[\"AdRevenueTotal16\"] = train[\"AdRevenueD14\"] + train[\"AdRevenueD15\"]\n",
    "\n",
    "\n",
    "# Retention için benzer sütunlar oluşturma (train seti)\n",
    "train[\"RetentionTotal2\"] = train[\"RetentionD0\"] + train[\"RetentionD1\"]\n",
    "train[\"RetentionTotal4\"] = train[\"RetentionD2\"] + train[\"RetentionD3\"]\n",
    "train[\"RetentionTotal6\"] = train[\"RetentionD4\"] + train[\"RetentionD5\"]\n",
    "train[\"RetentionTotal8\"] = train[\"RetentionD6\"] + train[\"RetentionD7\"]\n",
    "train[\"RetentionTotal10\"] = train[\"RetentionD8\"] + train[\"RetentionD9\"]\n",
    "train[\"RetentionTotal12\"] = train[\"RetentionD10\"] + train[\"RetentionD11\"]\n",
    "train[\"RetentionTotal14\"] = train[\"RetentionD12\"] + train[\"RetentionD13\"]\n",
    "train[\"RetentionTotal16\"] = train[\"RetentionD14\"] + train[\"RetentionD15\"]\n",
    "\n",
    "\n",
    "\n",
    "# LevelAdvancedCountTotal\n",
    "test[\"LevelAdvancedCountTotal2\"] = test[\"LevelAdvancedCountD0\"] + test[\"LevelAdvancedCountD1\"]\n",
    "test[\"LevelAdvancedCountTotal4\"] = test[\"LevelAdvancedCountD2\"] + test[\"LevelAdvancedCountD3\"]\n",
    "test[\"LevelAdvancedCountTotal6\"] = test[\"LevelAdvancedCountD4\"] + test[\"LevelAdvancedCountD5\"]\n",
    "test[\"LevelAdvancedCountTotal8\"] = test[\"LevelAdvancedCountD6\"] + test[\"LevelAdvancedCountD7\"]\n",
    "test[\"LevelAdvancedCountTotal10\"] = test[\"LevelAdvancedCountD8\"] + test[\"LevelAdvancedCountD9\"]\n",
    "test[\"LevelAdvancedCountTotal12\"] = test[\"LevelAdvancedCountD10\"] + test[\"LevelAdvancedCountD11\"]\n",
    "test[\"LevelAdvancedCountTotal14\"] = test[\"LevelAdvancedCountD12\"] + test[\"LevelAdvancedCountD13\"]\n",
    "test[\"LevelAdvancedCountTotal16\"] = test[\"LevelAdvancedCountD14\"] + test[\"LevelAdvancedCountD15\"]\n",
    "\n",
    "# Level Duration\n",
    "test[\"LevelDurationTotal2\"] = test[\"Level_1_Duration\"] + test[\"Level_2_Duration\"]\n",
    "test[\"LevelDurationTotal4\"] = test[\"Level_3_Duration\"] + test[\"Level_4_Duration\"]\n",
    "test[\"LevelDurationTotal6\"] = test[\"Level_5_Duration\"] + test[\"Level_6_Duration\"]\n",
    "test[\"LevelDurationTotal8\"] = test[\"Level_7_Duration\"] + test[\"Level_8_Duration\"]\n",
    "test[\"LevelDurationTotal10\"] = test[\"Level_9_Duration\"] + test[\"Level_10_Duration\"]\n",
    "\n",
    "# AdRevenue\n",
    "test[\"AdRevenueTotal2\"] = test[\"AdRevenueD0\"] + test[\"AdRevenueD1\"]\n",
    "test[\"AdRevenueTotal4\"] = test[\"AdRevenueD2\"] + test[\"AdRevenueD3\"]\n",
    "test[\"AdRevenueTotal6\"] = test[\"AdRevenueD4\"] + test[\"AdRevenueD5\"]\n",
    "test[\"AdRevenueTotal8\"] = test[\"AdRevenueD6\"] + test[\"AdRevenueD7\"]\n",
    "test[\"AdRevenueTotal10\"] = test[\"AdRevenueD8\"] + test[\"AdRevenueD9\"]\n",
    "test[\"AdRevenueTotal12\"] = test[\"AdRevenueD10\"] + test[\"AdRevenueD11\"]\n",
    "test[\"AdRevenueTotal14\"] = test[\"AdRevenueD12\"] + test[\"AdRevenueD13\"]\n",
    "test[\"AdRevenueTotal16\"] = test[\"AdRevenueD14\"] + test[\"AdRevenueD15\"]\n",
    "\n",
    "\n",
    "# IAPRevenue için benzer sütunlar oluşturma (test seti)\n",
    "test[\"IAPRevenueTotal2\"] = test[\"IAPRevenueD0\"] + test[\"IAPRevenueD1\"]\n",
    "test[\"IAPRevenueTotal4\"] = test[\"IAPRevenueD2\"] + test[\"IAPRevenueD3\"]\n",
    "test[\"IAPRevenueTotal6\"] = test[\"IAPRevenueD4\"] + test[\"IAPRevenueD5\"]\n",
    "test[\"IAPRevenueTotal8\"] = test[\"IAPRevenueD6\"] + test[\"IAPRevenueD7\"]\n",
    "test[\"IAPRevenueTotal10\"] = test[\"IAPRevenueD8\"] + test[\"IAPRevenueD9\"]\n",
    "test[\"IAPRevenueTotal12\"] = test[\"IAPRevenueD10\"] + test[\"IAPRevenueD11\"]\n",
    "test[\"IAPRevenueTotal14\"] = test[\"IAPRevenueD12\"] + test[\"IAPRevenueD13\"]\n",
    "test[\"IAPRevenueTotal16\"] = test[\"IAPRevenueD14\"] + test[\"IAPRevenueD15\"]\n",
    "\n",
    "\n",
    "# Retention için benzer sütunlar oluşturma (test seti)\n",
    "test[\"RetentionTotal2\"] = test[\"RetentionD0\"] + test[\"RetentionD1\"]\n",
    "test[\"RetentionTotal4\"] = test[\"RetentionD2\"] + test[\"RetentionD3\"]\n",
    "test[\"RetentionTotal6\"] = test[\"RetentionD4\"] + test[\"RetentionD5\"]\n",
    "test[\"RetentionTotal8\"] = test[\"RetentionD6\"] + test[\"RetentionD7\"]\n",
    "test[\"RetentionTotal10\"] = test[\"RetentionD8\"] + test[\"RetentionD9\"]\n",
    "test[\"RetentionTotal12\"] = test[\"RetentionD10\"] + test[\"RetentionD11\"]\n",
    "test[\"RetentionTotal14\"] = test[\"RetentionD12\"] + test[\"RetentionD13\"]\n",
    "test[\"RetentionTotal16\"] = test[\"RetentionD14\"] + test[\"RetentionD15\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:20.255202Z",
     "start_time": "2024-09-12T14:07:20.036270Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#LevelAdvancedCountTotal\n",
    "train[\"LevelAdvancedCountTotal5\"] = (\n",
    "        train[\"LevelAdvancedCountD0\"] + train[\"LevelAdvancedCountD1\"] + train[\"LevelAdvancedCountD2\"] + train[\"LevelAdvancedCountD3\"]+ train[\"LevelAdvancedCountD4\"]\n",
    ")\n",
    "\n",
    "train[\"LevelAdvancedCountTotal10\"] = (\n",
    "        train[\"LevelAdvancedCountD5\"] + train[\"LevelAdvancedCountD6\"] + train[\"LevelAdvancedCountD7\"] + train[\"LevelAdvancedCountD8\"]+ train[\"LevelAdvancedCountD9\"]\n",
    ")\n",
    "\n",
    "train[\"LevelAdvancedCountTotal15\"] = (\n",
    "        train[\"LevelAdvancedCountD10\"] + train[\"LevelAdvancedCountD11\"] + train[\"LevelAdvancedCountD12\"] + train[\"LevelAdvancedCountD13\"]+ train[\"LevelAdvancedCountD14\"]+train[\"LevelAdvancedCountD15\"]\n",
    ")\n",
    "\n",
    "#Level Duration \n",
    "train[\"LevelDurationTotal5\"] = (\n",
    "        train[\"Level_1_Duration\"] + train[\"Level_2_Duration\"] + train[\"Level_3_Duration\"] +\n",
    "        train[\"Level_4_Duration\"] + train[\"Level_5_Duration\"]\n",
    ")\n",
    "train[\"LevelDurationTotal10\"] = (\n",
    "        train[\"Level_6_Duration\"] + train[\"Level_7_Duration\"] + train[\"Level_8_Duration\"] +\n",
    "        train[\"Level_9_Duration\"] + train[\"Level_10_Duration\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#AdRevenue\n",
    "train[\"AdRevenueTotal5\"] = (\n",
    "        train[\"AdRevenueD0\"] + train[\"AdRevenueD1\"] + train[\"AdRevenueD2\"] +\n",
    "        train[\"AdRevenueD3\"] + train[\"AdRevenueD4\"]\n",
    ")\n",
    "train[\"AdRevenueTotal10\"] = (\n",
    "        train[\"AdRevenueD5\"] + train[\"AdRevenueD6\"] + train[\"AdRevenueD7\"] +\n",
    "        train[\"AdRevenueD8\"] + train[\"AdRevenueD9\"]\n",
    ")\n",
    "train[\"AdRevenueTotal15\"] = (\n",
    "        train[\"AdRevenueD10\"] + train[\"AdRevenueD11\"] + train[\"AdRevenueD12\"] +\n",
    "        train[\"AdRevenueD13\"] + train[\"AdRevenueD14\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Retention Total\n",
    "train[\"RetentionTotal5\"] = (\n",
    "        train[\"RetentionD0\"] + train[\"RetentionD1\"] + train[\"RetentionD2\"] +\n",
    "        train[\"RetentionD3\"] + train[\"RetentionD4\"]\n",
    ")\n",
    "train[\"RetentionTotal10\"] = (\n",
    "        train[\"RetentionD5\"] + train[\"RetentionD6\"] + train[\"RetentionD7\"] +\n",
    "        train[\"RetentionD8\"] + train[\"RetentionD9\"]\n",
    ")\n",
    "train[\"RetentionTotal15\"] = (\n",
    "        train[\"RetentionD10\"] + train[\"RetentionD11\"] + train[\"RetentionD12\"] +\n",
    "        train[\"RetentionD13\"] + train[\"RetentionD14\"]\n",
    ")\n",
    "\n",
    "# IAPRevenue Total\n",
    "train[\"IAPRevenueTotal5\"] = (\n",
    "        train[\"IAPRevenueD0\"] + train[\"IAPRevenueD1\"] + train[\"IAPRevenueD2\"] +\n",
    "        train[\"IAPRevenueD3\"] + train[\"IAPRevenueD4\"]\n",
    ")\n",
    "train[\"IAPRevenueTotal10\"] = (\n",
    "        train[\"IAPRevenueD5\"] + train[\"IAPRevenueD6\"] + train[\"IAPRevenueD7\"] +\n",
    "        train[\"IAPRevenueD8\"] + train[\"IAPRevenueD9\"]\n",
    ")\n",
    "train[\"IAPRevenueTotal15\"] = (\n",
    "        train[\"IAPRevenueD10\"] + train[\"IAPRevenueD11\"] + train[\"IAPRevenueD12\"] +\n",
    "        train[\"IAPRevenueD13\"] + train[\"IAPRevenueD14\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#LevelAdvancedCountTotal\n",
    "test[\"LevelAdvancedCountTotal5\"] = (\n",
    "        test[\"LevelAdvancedCountD0\"] + test[\"LevelAdvancedCountD1\"] + test[\"LevelAdvancedCountD2\"] + test[\"LevelAdvancedCountD3\"]+ test[\"LevelAdvancedCountD4\"]\n",
    ")\n",
    "\n",
    "test[\"LevelAdvancedCountTotal10\"] = (\n",
    "        test[\"LevelAdvancedCountD5\"] + test[\"LevelAdvancedCountD6\"] + test[\"LevelAdvancedCountD7\"] + test[\"LevelAdvancedCountD8\"]+ test[\"LevelAdvancedCountD9\"]\n",
    ")\n",
    "\n",
    "test[\"LevelAdvancedCountTotal15\"] = (\n",
    "        test[\"LevelAdvancedCountD10\"] + test[\"LevelAdvancedCountD11\"] + test[\"LevelAdvancedCountD12\"] + test[\"LevelAdvancedCountD13\"]+ test[\"LevelAdvancedCountD14\"]+test[\"LevelAdvancedCountD15\"]\n",
    ")\n",
    "\n",
    "\n",
    "#Level Duration \n",
    "test[\"LevelDurationTotal5\"] = (\n",
    "        test[\"Level_1_Duration\"] + test[\"Level_2_Duration\"] + test[\"Level_3_Duration\"] +\n",
    "        test[\"Level_4_Duration\"] + test[\"Level_5_Duration\"]\n",
    ")\n",
    "test[\"LevelDurationTotal10\"] = (\n",
    "        test[\"Level_6_Duration\"] + test[\"Level_7_Duration\"] + test[\"Level_8_Duration\"] +\n",
    "        test[\"Level_9_Duration\"] + test[\"Level_10_Duration\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#AdRevenue\n",
    "test[\"AdRevenueTotal5\"] = (\n",
    "        test[\"AdRevenueD0\"] + test[\"AdRevenueD1\"] + test[\"AdRevenueD2\"] +\n",
    "        test[\"AdRevenueD3\"] + test[\"AdRevenueD4\"]\n",
    ")\n",
    "test[\"AdRevenueTotal10\"] = (\n",
    "        test[\"AdRevenueD5\"] + test[\"AdRevenueD6\"] + test[\"AdRevenueD7\"] +\n",
    "        test[\"AdRevenueD8\"] + test[\"AdRevenueD9\"]\n",
    ")\n",
    "test[\"AdRevenueTotal15\"] = (\n",
    "        test[\"AdRevenueD10\"] + test[\"AdRevenueD11\"] + test[\"AdRevenueD12\"] +\n",
    "        test[\"AdRevenueD13\"] + test[\"AdRevenueD14\"]\n",
    ")\n",
    "\n",
    "# Aynı işlemleri test setine de uyguluyoruz\n",
    "test[\"RetentionTotal5\"] = (\n",
    "        test[\"RetentionD0\"] + test[\"RetentionD1\"] + test[\"RetentionD2\"] +\n",
    "        test[\"RetentionD3\"] + test[\"RetentionD4\"]\n",
    ")\n",
    "test[\"RetentionTotal10\"] = (\n",
    "        test[\"RetentionD5\"] + test[\"RetentionD6\"] + test[\"RetentionD7\"] +\n",
    "        test[\"RetentionD8\"] + test[\"RetentionD9\"]\n",
    ")\n",
    "test[\"RetentionTotal15\"] = (\n",
    "        test[\"RetentionD10\"] + test[\"RetentionD11\"] + test[\"RetentionD12\"] +\n",
    "        test[\"RetentionD13\"] + test[\"RetentionD14\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Aynı işlemleri test setine de uyguluyoruz\n",
    "test[\"IAPRevenueTotal5\"] = (\n",
    "        test[\"IAPRevenueD0\"] + test[\"IAPRevenueD1\"] + test[\"IAPRevenueD2\"] +\n",
    "        test[\"IAPRevenueD3\"] + test[\"IAPRevenueD4\"]\n",
    ")\n",
    "test[\"IAPRevenueTotal10\"] = (\n",
    "        test[\"IAPRevenueD5\"] + test[\"IAPRevenueD6\"] + test[\"IAPRevenueD7\"] +\n",
    "        test[\"IAPRevenueD8\"] + test[\"IAPRevenueD9\"]\n",
    ")\n",
    "test[\"IAPRevenueTotal15\"] = (\n",
    "        test[\"IAPRevenueD10\"] + test[\"IAPRevenueD11\"] + test[\"IAPRevenueD12\"] +\n",
    "        test[\"IAPRevenueD13\"] + test[\"IAPRevenueD14\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:24.160902Z",
     "start_time": "2024-09-12T14:07:20.258202Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train[\"first_prediction\"]=train[\"first_prediction\"].interpolate(method=\"linear\")\n",
    "test[\"first_prediction\"]=test[\"first_prediction\"].interpolate(method=\"linear\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#BAŞARISIZ\n",
    "#network_revenue_avg = test.groupby('ad_network')['Total_Revenue'].mean().reset_index()\n",
    "#network_revenue_avg.columns = ['ad_network', 'AdNetwork_Revenue_Avg']\n",
    "\n",
    "# Kullanıcı verisine ekleyelim\n",
    "#test = test.merge(network_revenue_avg, on='ad_network', how='left')\n",
    "#train[\"first_open_timestamp\"]=np.log1p(train[\"first_open_timestamp\"])\n",
    "#test[\"first_open_timestamp\"]=np.log1p(test[\"first_open_timestamp\"])\n",
    "\n",
    "#test[\"local_first_open_timestamp\"]=np.log1p(test[\"local_first_open_timestamp\"])\n",
    "#train[\"local_first_open_timestamp\"]=np.log1p(train[\"local_first_open_timestamp\"])\n",
    "\n",
    "\n",
    "# İlk IAP satın almasının yapıldığı günü bulmak için bir fonksiyon yazalım\n",
    "#def days_to_first_iap(row):\n",
    "#    for i in range(1, 16):\n",
    "#        if row[f'IAPRevenueD{i}'] > 0:\n",
    "#            return i\n",
    "#    return None\n",
    "\n",
    "# Kullanıcı başına kaçıncı gün ilk satın almanın yapıldığını hesaplayalım\n",
    "#train['Days_to_First_IAP'] = train.apply(days_to_first_iap, axis=1)\n",
    "#test[\"Days_to_First_IAP\"]=train.apply(days_to_first_iap,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "train['Total_Revenue'] = train.filter(like='AdRevenueD').sum(axis=1) + train.filter(like='IAPRevenueD').sum(axis=1)\n",
    "test['Total_Revenue'] = test.filter(like='AdRevenueD').sum(axis=1) + test.filter(like='IAPRevenueD').sum(axis=1)\n",
    "######################\n",
    "\n",
    "#############################\n",
    "network_revenue_avg = train.groupby('ad_network')['Total_Revenue'].mean().reset_index()\n",
    "network_revenue_avg.columns = ['ad_network', 'AdNetwork_Revenue_Avg']\n",
    "train = train.merge(network_revenue_avg, on='ad_network', how='left')\n",
    "\n",
    "\n",
    "network_revenue_avg = test.groupby('ad_network')['Total_Revenue'].mean().reset_index()\n",
    "network_revenue_avg.columns = ['ad_network', 'AdNetwork_Revenue_Avg']\n",
    "test = test.merge(network_revenue_avg, on='ad_network', how='left')\n",
    "###############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "# Device Brand'e göre ortalama gelir\n",
    "device_brand_revenue_avg = train.groupby('device_brand')['Total_Revenue'].mean().reset_index()\n",
    "device_brand_revenue_avg.columns = ['device_brand', 'Device_Brand_Revenue_Avg']\n",
    "train = train.merge(device_brand_revenue_avg, on='device_brand', how='left')\n",
    "\n",
    "device_brand_revenue_avg = test.groupby('device_brand')['Total_Revenue'].mean().reset_index()\n",
    "device_brand_revenue_avg.columns = ['device_brand', 'Device_Brand_Revenue_Avg']\n",
    "test = test.merge(device_brand_revenue_avg, on='device_brand', how='left')\n",
    "###############################\n",
    "\n",
    "\n",
    "#############################\n",
    "# Ülke, cihaz ve platform kombinasyonuna göre ortalama gelir\n",
    "country_device_platform_revenue_avg = train.groupby(['country', 'device_category', 'platform'])['Total_Revenue'].mean().reset_index()\n",
    "country_device_platform_revenue_avg.columns = ['country', 'device_category', 'platform', 'Country_Device_Platform_Revenue_Avg']\n",
    "train = train.merge(country_device_platform_revenue_avg, on=['country', 'device_category', 'platform'], how='left')\n",
    "\n",
    "\n",
    "country_device_platform_revenue_avg = test.groupby(['country', 'device_category', 'platform'])['Total_Revenue'].mean().reset_index()\n",
    "country_device_platform_revenue_avg.columns = ['country', 'device_category', 'platform', 'Country_Device_Platform_Revenue_Avg']\n",
    "test = test.merge(country_device_platform_revenue_avg, on=['country', 'device_category', 'platform'], how='left')\n",
    "###############################\n",
    "\n",
    "#train[\"first_open_date\"] = pd.to_datetime(train[\"first_open_date\"])\n",
    "#train[\"first_open_timestamp\"] = pd.to_timedelta(train[\"first_open_timestamp\"])\n",
    "#train[\"local_first_open_timestamp\"] = pd.to_timedelta(train[\"local_first_open_timestamp\"])\n",
    "\n",
    "#test[\"first_open_date\"] = pd.to_datetime(test[\"first_open_date\"])\n",
    "#test[\"first_open_timestamp\"] = pd.to_timedelta(test[\"first_open_timestamp\"])\n",
    "#test[\"local_first_open_timestamp\"] = pd.to_timedelta(test[\"local_first_open_timestamp\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:24.224441Z",
     "start_time": "2024-09-12T14:07:24.162294Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#score 1 BAŞARILI\n",
    "train[\"score1\"]=(train[\"LevelAdvancedCountD10\"]+train[\"LevelAdvancedCountD11\"]+train[\"LevelAdvancedCountD12\"]+train[\"LevelAdvancedCountD13\"])*train[\"Total_Revenue\"]\n",
    "test[\"score1\"]=(test[\"LevelAdvancedCountD10\"]+test[\"LevelAdvancedCountD11\"]+test[\"LevelAdvancedCountD12\"]+test[\"LevelAdvancedCountD13\"])*test[\"Total_Revenue\"]\n",
    "\n",
    "#score 2 BAŞARILI\n",
    "train[\"score2\"]=(train[\"Country_Device_Platform_Revenue_Avg\"]+train[\"first_prediction\"])**2\n",
    "test[\"score2\"]=(test[\"Country_Device_Platform_Revenue_Avg\"]+test[\"first_prediction\"])**2\n",
    "\n",
    "#Score3 BAŞARISIZ\n",
    "#train[\"score3\"]=(train[\"AdRevenueD13\"]+train[\"AdRevenueD1\"]+train[\"AdRevenueD12\"]+train[\"AdRevenueD3\"]+train[\"AdRevenueD4\"])**2\n",
    "\n",
    "#test[\"score3\"]=(test[\"AdRevenueD13\"]+test[\"AdRevenueD1\"]+test[\"AdRevenueD12\"]+test[\"AdRevenueD3\"]+test[\"AdRevenueD4\"])**2\n",
    "\n",
    "#Score 3 BAŞARILI\n",
    "train[\"score3\"]=(train[\"LevelAdvancedCountTotal15\"]+train[\"LevelAdvancedCountTotal10\"]+train[\"LevelAdvancedCountTotal5\"])**2\n",
    "test[\"score3\"]=(test[\"LevelAdvancedCountTotal15\"]+test[\"LevelAdvancedCountTotal10\"]+train[\"LevelAdvancedCountTotal5\"])**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:24.240616Z",
     "start_time": "2024-09-12T14:07:24.225442Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"score4\"]=(train[\"Total_Revenue\"]+train[\"first_prediction\"])**2\n",
    "test[\"score4\"]=(test[\"Total_Revenue\"]+test[\"first_prediction\"])**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:25.935915Z",
     "start_time": "2024-09-12T14:07:24.241627Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdRevenueD0 (-0.059846108900488616, 0.0997435148341477)\n",
      "AdRevenueD0 (-0.05986737250494386, 0.09977895417490643)\n",
      "AdRevenueD1 (-0.008947809449015288, 0.014913015748358814)\n",
      "AdRevenueD1 (-0.009000000078230999, 0.015000000130384999)\n",
      "AdRevenueD0 True\n",
      "AdRevenueD0 True\n",
      "AdRevenueD1 True\n",
      "AdRevenueD1 True\n"
     ]
    }
   ],
   "source": [
    "def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "def check_outlier(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def replace_with_thresholds(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
    "\n",
    "liste=[\"AdRevenueD0\",\"AdRevenueD1\"]\n",
    "\n",
    "for col in liste:\n",
    "    print(col, outlier_thresholds(train, col))\n",
    "    print(col, outlier_thresholds(test, col))\n",
    "\n",
    "for col in liste:\n",
    "    print(col, check_outlier(train, col))\n",
    "    print(col, check_outlier(test, col))\n",
    "\n",
    "for col in liste:\n",
    "    col, replace_with_thresholds(train, col)\n",
    "    col, replace_with_thresholds(test, col)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:25.951851Z",
     "start_time": "2024-09-12T14:07:25.936835Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#silinecekler=pd.read_csv(\"SİLİNECEKLER.csv\")\n",
    "#silinecek=silinecekler[\"Feature\"]\n",
    "\n",
    "#a=test.columns\n",
    "# Ortak elemanları bulmak için set kesişimini kullanıyoruz\n",
    "#ortak_liste = list(set(silinecek) & set(a))\n",
    "\n",
    "\n",
    "#train.drop(columns=ortak_liste,axis=1,inplace=True)\n",
    "#test.drop(columns=ortak_liste,axis=1,inplace=True)\n",
    "#train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:25.967360Z",
     "start_time": "2024-09-12T14:07:25.953842Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:47.357319Z",
     "start_time": "2024-09-12T14:07:25.969353Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((878594, 110), (585730, 109))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"first_prediction\"]=train[\"first_prediction\"].interpolate(method=\"linear\")\n",
    "test[\"first_prediction\"]=test[\"first_prediction\"].interpolate(method=\"linear\")\n",
    "\n",
    "train['ad_network'] = train['ad_network'].fillna('organic')\n",
    "test['ad_network'] = test['ad_network'].fillna('organic')\n",
    "\n",
    "\n",
    "# OrdinalEncoder'ı tanıml\n",
    "oe = OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
    "\n",
    "# Tüm string kolonları bul\n",
    "string_cols = test.select_dtypes(include=['object',\"bool\"]).columns\n",
    "\n",
    "# Tüm string kolonları dolas\n",
    "for col in string_cols:\n",
    "    # Convert column to string type to handle any mixed data types\n",
    "    test[col] = train[col].astype(str)\n",
    "    train[col] = test[col].astype(str)\n",
    "\n",
    "    # Fit OrdinalEncoder\n",
    "    train[[col]] = oe.fit_transform(train[[col]])\n",
    "    test[[col]] = oe.transform(test[[col]])\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:47.373318Z",
     "start_time": "2024-09-12T14:07:47.359342Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:47.389357Z",
     "start_time": "2024-09-12T14:07:47.375313Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'first_prediction',\n",
       " 'LevelAdvancedCountD0',\n",
       " 'LevelAdvancedCountD1',\n",
       " 'LevelAdvancedCountD2',\n",
       " 'LevelAdvancedCountD3',\n",
       " 'LevelAdvancedCountD4',\n",
       " 'LevelAdvancedCountD5',\n",
       " 'LevelAdvancedCountD6',\n",
       " 'LevelAdvancedCountD7',\n",
       " 'LevelAdvancedCountD8',\n",
       " 'LevelAdvancedCountD9',\n",
       " 'LevelAdvancedCountD10',\n",
       " 'LevelAdvancedCountD11',\n",
       " 'LevelAdvancedCountD12',\n",
       " 'LevelAdvancedCountD13',\n",
       " 'LevelAdvancedCountD14',\n",
       " 'LevelAdvancedCountD15',\n",
       " 'Level_1_Duration',\n",
       " 'Level_2_Duration',\n",
       " 'Level_3_Duration',\n",
       " 'Level_4_Duration',\n",
       " 'Level_5_Duration',\n",
       " 'Level_6_Duration',\n",
       " 'Level_7_Duration',\n",
       " 'Level_8_Duration',\n",
       " 'Level_9_Duration',\n",
       " 'Level_10_Duration',\n",
       " 'AdRevenueD0',\n",
       " 'AdRevenueD1',\n",
       " 'AdRevenueD2',\n",
       " 'AdRevenueD3',\n",
       " 'AdRevenueD4',\n",
       " 'AdRevenueD5',\n",
       " 'AdRevenueD6',\n",
       " 'AdRevenueD7',\n",
       " 'AdRevenueD8',\n",
       " 'AdRevenueD9',\n",
       " 'AdRevenueD10',\n",
       " 'AdRevenueD11',\n",
       " 'AdRevenueD12',\n",
       " 'AdRevenueD13',\n",
       " 'AdRevenueD14',\n",
       " 'AdRevenueD15']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols_testFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:47.405033Z",
     "start_time": "2024-09-12T14:07:47.390377Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:07:49.076512Z",
     "start_time": "2024-09-12T14:07:47.407042Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10441335 1884072\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum().sum(),test.isnull().sum().sum())\n",
    "train.fillna(-1,axis=1,inplace=True),test.fillna(-1,axis=1,inplace=True)\n",
    "print(train.isnull().sum().sum(),test.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:13:09.622443Z",
     "start_time": "2024-09-12T14:07:49.077530Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: RMSE = 1.8783\n",
      "Fold 2: RMSE = 1.3093\n",
      "Fold 3: RMSE = 1.6310\n",
      "Fold 4: RMSE = 1.5847\n",
      "Fold 5: RMSE = 1.6869\n",
      "Average RMSE = 1.6180\n"
     ]
    }
   ],
   "source": [
    "y = train[\"TARGET\"]\n",
    "X = train.drop(columns=[\"TARGET\"],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Repeated K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=24)\n",
    "scores = []\n",
    "test_preds = np.zeros(len(test))  # Assuming `test` is your test set\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create and train CatBoostRegressor model\n",
    "    model = CatBoostRegressor(random_state=41,verbose=False)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE score\n",
    "    score = mean_squared_error(y_test, y_pred,squared=False)  # RMSE\n",
    "    scores.append(score)\n",
    "\n",
    "    print(f\"Fold {fold + 1}: RMSE = {score:.4f}\")\n",
    "\n",
    "    # Average test set predictions across folds\n",
    "    test_preds += model.predict(test) / kf.n_splits\n",
    "\n",
    "# Calculate average RMSE score\n",
    "mean_score = np.mean(scores)\n",
    "print(f\"Average RMSE = {mean_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:15:38.928416Z",
     "start_time": "2024-09-12T14:15:37.987521Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame({\"ID\":ID,\"TARGET\":test_preds})\n",
    "data.set_index(\"ID\",inplace=True)\n",
    "data.to_csv(\"submission7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:15:39.647906Z",
     "start_time": "2024-09-12T14:15:39.642905Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:15:40.793882Z",
     "start_time": "2024-09-12T14:15:40.785879Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>878594</th>\n",
       "      <td>0.014308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878595</th>\n",
       "      <td>0.009347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878596</th>\n",
       "      <td>0.017519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878597</th>\n",
       "      <td>0.563819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878598</th>\n",
       "      <td>0.017639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TARGET\n",
       "ID              \n",
       "878594  0.014308\n",
       "878595  0.009347\n",
       "878596  0.017519\n",
       "878597  0.563819\n",
       "878598  0.017639"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "#1.6020 num_but_cat columnlar\n",
    "#1.6047 cat_but_not_car_testUsers+cat_but_not_car_testFeatures\n",
    "#1.5963 cat_but_car_testFeatures+cat_but_car_testUsers\n",
    "#1.6047   cat_cols_testFeatures+cat_cols_testUsers\n",
    "#1.5963          outlier değer olmadan\n",
    "\n",
    "#1.5959\n",
    "\n",
    "#1.6020 num_but_cat columnlar\n",
    "#1.6047 cat_but_not_car_testUsers+cat_but_not_car_testFeatures\n",
    "#1.5963 cat_but_car_testFeatures+cat_but_car_testUsers\n",
    "#1.6047  cat_cols_testFeatures+cat_cols_testUsers\n",
    "# 2.5      num_cols_testUsers+num_cols_testFeatures\n",
    "#1.65\n",
    "#1.6497\n",
    "#1.6095\n",
    "#1.6130 => en iyi skor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# OrdinalEncoder'ı tanımla\n",
    "oe = OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
    "traincopy=train[:10000]\n",
    "a=traincopy[\"TARGET\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tüm string kolonları bul\n",
    "string_cols = test.select_dtypes(include=['object',\"bool\"]).columns\n",
    "\n",
    "# Tüm string kolonları dolas\n",
    "for col in string_cols:\n",
    "    # Convert column to string type to handle any mixed data types\n",
    "    traincopy[col] = traincopy[col].astype(str)\n",
    "\n",
    "    # Fit OrdinalEncoder\n",
    "    traincopy[[col]] = oe.fit_transform(traincopy[[col]])\n",
    "    \n",
    "traincopy=traincopy[trainFeaturescopy.columns]\n",
    "\n",
    "traincopy=pd.concat([traincopy,a],axis=1)\n",
    "traincopy.drop(\"ID\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#RetentionTotal\n",
    "traincopy[\"RetentionTotal5\"] = (\n",
    "        traincopy[\"RetentionD0\"] + traincopy[\"RetentionD1\"] + traincopy[\"RetentionD2\"] +\n",
    "        traincopy[\"RetentionD3\"] + traincopy[\"RetentionD4\"]\n",
    ")\n",
    "traincopy[\"RetentionTotal10\"] = (\n",
    "        traincopy[\"RetentionD5\"] + traincopy[\"RetentionD6\"] + traincopy[\"RetentionD7\"] +\n",
    "        traincopy[\"RetentionD8\"] + traincopy[\"RetentionD9\"]\n",
    ")\n",
    "traincopy[\"RetentionTotal15\"] = (\n",
    "        traincopy[\"RetentionD10\"] + traincopy[\"RetentionD11\"] + traincopy[\"RetentionD12\"] +\n",
    "        traincopy[\"RetentionD13\"] + traincopy[\"RetentionD14\"] + traincopy[\"RetentionD15\"]\n",
    ")\n",
    "\n",
    "#LevelAdvancedCountTotal\n",
    "traincopy[\"LevelAdvancedCountTotal5\"] = (\n",
    "        traincopy[\"LevelAdvancedCountD0\"] + traincopy[\"LevelAdvancedCountD1\"] + traincopy[\"LevelAdvancedCountD2\"] + traincopy[\"LevelAdvancedCountD3\"]+ traincopy[\"LevelAdvancedCountD4\"]\n",
    ")\n",
    "\n",
    "traincopy[\"LevelAdvancedCountTotal10\"] = (\n",
    "        traincopy[\"LevelAdvancedCountD5\"] + traincopy[\"LevelAdvancedCountD6\"] + traincopy[\"LevelAdvancedCountD7\"] + traincopy[\"LevelAdvancedCountD8\"]+ traincopy[\"LevelAdvancedCountD9\"]\n",
    ")\n",
    "\n",
    "traincopy[\"LevelAdvancedCountTotal15\"] = (\n",
    "        traincopy[\"LevelAdvancedCountD10\"] + traincopy[\"LevelAdvancedCountD11\"] + traincopy[\"LevelAdvancedCountD12\"] + traincopy[\"LevelAdvancedCountD13\"]+ traincopy[\"LevelAdvancedCountD14\"]+traincopy[\"LevelAdvancedCountD15\"]\n",
    ")\n",
    "\n",
    "liste=[\"LevelDurationTotal5\",\"LevelDurationTotal10\",\"LevelAdvancedCountTotal5\",\"LevelAdvancedCountTotal10\",\"LevelAdvancedCountTotal15\",\n",
    "       \"RetentionTotal5\",\"RetentionTotal10\",\"RetentionTotal15\",\"IAPRevenueTotal5\",\"IAPRevenueTotal15\"]\n",
    "#Level Duration \n",
    "traincopy[\"LevelDurationTotal5\"] = (\n",
    "        traincopy[\"Level_1_Duration\"] + traincopy[\"Level_2_Duration\"] + traincopy[\"Level_3_Duration\"] +\n",
    "        traincopy[\"Level_4_Duration\"] + traincopy[\"Level_5_Duration\"]\n",
    ")\n",
    "traincopy[\"LevelDurationTotal10\"] = (\n",
    "        traincopy[\"Level_6_Duration\"] + traincopy[\"Level_7_Duration\"] + traincopy[\"Level_8_Duration\"] +\n",
    "        traincopy[\"Level_9_Duration\"] + traincopy[\"Level_10_Duration\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#AdRevenue\n",
    "traincopy[\"AdRevenueTotal5\"] = (\n",
    "        traincopy[\"AdRevenueD0\"] + traincopy[\"AdRevenueD1\"] + traincopy[\"AdRevenueD2\"] +\n",
    "        traincopy[\"AdRevenueD3\"] + traincopy[\"AdRevenueD4\"]\n",
    ")\n",
    "traincopy[\"AdRevenueTotal10\"] = (\n",
    "        traincopy[\"AdRevenueD5\"] + traincopy[\"AdRevenueD6\"] + traincopy[\"AdRevenueD7\"] +\n",
    "        traincopy[\"AdRevenueD8\"] + traincopy[\"AdRevenueD9\"]\n",
    ")\n",
    "traincopy[\"AdRevenueTotal15\"] = (\n",
    "        traincopy[\"AdRevenueD10\"] + traincopy[\"AdRevenueD11\"] + traincopy[\"AdRevenueD12\"] +\n",
    "        traincopy[\"AdRevenueD13\"] + traincopy[\"AdRevenueD14\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "traincopy[\"IAPRevenueTotal5\"] = (\n",
    "        traincopy[\"IAPRevenueD0\"] + traincopy[\"IAPRevenueD1\"] + traincopy[\"IAPRevenueD2\"] +\n",
    "        traincopy[\"IAPRevenueD3\"] + traincopy[\"IAPRevenueD4\"]\n",
    ")\n",
    "traincopy[\"IAPRevenueTotal10\"] = (\n",
    "        traincopy[\"IAPRevenueD5\"] + traincopy[\"IAPRevenueD6\"] + traincopy[\"IAPRevenueD7\"] +\n",
    "        traincopy[\"IAPRevenueD8\"] + traincopy[\"IAPRevenueD9\"]\n",
    ")\n",
    "traincopy[\"IAPRevenueTotal15\"] = (\n",
    "        traincopy[\"IAPRevenueD10\"] + traincopy[\"IAPRevenueD11\"] + traincopy[\"IAPRevenueD12\"] +\n",
    "        traincopy[\"IAPRevenueD13\"] + traincopy[\"IAPRevenueD14\"]\n",
    ")\n",
    "traincopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "#TEST ET NÜMERİK\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "def fill_na_forward(data, col):\n",
    "    data[col] = train[col]\n",
    "    print(data[col].isnull().sum())\n",
    "    data[col].fillna(method='ffill', inplace=True)\n",
    "\n",
    "def fill_na_backward(data, col):\n",
    "    data[col] = train[col]\n",
    "    print(data[col].isnull().sum())\n",
    "    data[col].fillna(method='bfill', inplace=True)\n",
    "\n",
    "def fill_na_mean(data, col):\n",
    "    data[col] = train[col]\n",
    "    print(data[col].isnull().sum())\n",
    "    mean_value = data[col].mean()\n",
    "    data[col].fillna(mean_value, inplace=True)\n",
    "\n",
    "def fill_na_median(data, col):\n",
    "    data[col] = train[col]\n",
    "    print(data[col].isnull().sum())\n",
    "    median_value = data[col].median()\n",
    "    data[col].fillna(median_value, inplace=True)\n",
    "\n",
    "def interpolate_values(data, col):\n",
    "    data[col] = train[col]\n",
    "    print(data[col].isnull().sum())\n",
    "    data[col].interpolate(method='linear', inplace=True)\n",
    "\n",
    "def RandomForestImpute(data, target_cols):\n",
    "    imputer = IterativeImputer(estimator=RandomForestRegressor())\n",
    "    data[target_cols] = imputer.fit_transform(data[target_cols])\n",
    "\n",
    "imputation_methods = [\n",
    "    fill_na_forward,\n",
    "    fill_na_backward,\n",
    "    fill_na_mean,\n",
    "    fill_na_median,\n",
    "    interpolate_values,\n",
    "]\n",
    "\n",
    "def apply_ml_and_report(data, target, method_name):\n",
    "    \"\"\"\n",
    "    This function sets up the AutoML pipeline using the imputed data and trains\n",
    "    the model to get the performance score.\n",
    "    \"\"\"\n",
    "    # Run AutoML using pycaret\n",
    "    clf = setup(data, target=target, html=False)\n",
    "    best_model = compare_models()\n",
    "\n",
    "    # Print or log the result along with the imputation method\n",
    "    print(f\"Age column imputed with {method_name}, best model: {best_model}\")\n",
    "\n",
    "# Loop through each method and apply it to the VIP column, then run AutoML on the Transported column\n",
    "for method in imputation_methods:\n",
    "    # Copy the data for each iteration to keep the imputations isolated\n",
    "    data_copy = traincopy.copy()\n",
    "\n",
    "    # Name of the current method for logging\n",
    "    method_name = method.__name__\n",
    "\n",
    "    # Apply the imputation method\n",
    "    target_col = 'first_prediction'\n",
    "    \n",
    "    if method_name == \"RandomForestImpute\":\n",
    "        target_features = liste\n",
    "        RandomForestImpute(data_copy, target_features)  # Pass target_features as an argument\n",
    "    else:\n",
    "        method(data_copy, target_col)  # Apply other imputation methods\n",
    "\n",
    "    # Now apply AutoML to the \"Transported\" column\n",
    "    apply_ml_and_report(data_copy, \"first_prediction\", method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#silme\n",
    "\n",
    "#prediction Trainuser randomforest\n",
    "\n",
    "def fill_na_median(data, col):  \n",
    "    median_value = data[col].median()\n",
    "    data[col].fillna(median_value, inplace=True)\n",
    "\n",
    "\n",
    "def RandomForestImpute(data, targetFeatureList, target):\n",
    "    # Hedef sütunun targetFeatureList içinde olmamasını sağla\n",
    "    targetFeatureList = [col for col in targetFeatureList if col in data.columns and col != target]\n",
    "\n",
    "    # Eksik verileri geçici olarak -1 ile doldur\n",
    "    data[targetFeatureList] = data[targetFeatureList].fillna(-1)\n",
    "\n",
    "\n",
    "    # Eğitim ve test setlerini oluştur\n",
    "    # Sadece hedef sütundaki eksik ve eksiksiz veriler üzerinde işlem yap\n",
    "    train_data_new = data[data[target].notnull()]\n",
    "    test_data_new = data[data[target].isnull()]\n",
    "\n",
    "    # Hedef ve özellik sütunlarını ayır\n",
    "    X_train = train_data_new[targetFeatureList]\n",
    "    y_train = train_data_new[target]\n",
    "    X_test = test_data_new[targetFeatureList]\n",
    "\n",
    "\n",
    "\n",
    "    # Modeli eğit ve eksik verileri tahmin et\n",
    "    model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Eksik olan değerleri tahmin et\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Tahmin edilen değerleri test setine ekle\n",
    "    data.loc[data[target].isnull(), target] = y_pred\n",
    "\n",
    "    # Eksik olan -1 değerlerini NaN ile değiştir\n",
    "    liste = [\"RoomService\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Age\",\"FoodCourt\"]\n",
    "    for i in liste:\n",
    "        if i != target:\n",
    "            data[i] = data[i].replace(-1, np.nan)\n",
    "    \n",
    "    return data\n",
    "# RandomForestImpute fonksiyonunu uygulayın\n",
    "\n",
    "\n",
    "RandomForestImpute(train, ['Age', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'RoomService'], 'RoomService')\n",
    "RandomForestImpute(test, ['Age', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'RoomService'], 'RoomService')\n",
    "RandomForestImpute(train, ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Age'], 'Age')\n",
    "RandomForestImpute(test, ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Age'], 'Age')\n",
    "RandomForestImpute(train, ['Age', 'FoodCourt', 'Spa', 'VRDeck', 'RoomService', 'ShoppingMall'], 'ShoppingMall')\n",
    "RandomForestImpute(test, ['Age', 'FoodCourt', 'Spa', 'VRDeck', 'RoomService', 'ShoppingMall'], 'ShoppingMall')\n",
    "RandomForestImpute(train, ['Age', 'FoodCourt', 'ShoppingMall', 'VRDeck', 'RoomService', 'Spa'], 'Spa')\n",
    "RandomForestImpute(test, ['Age', 'FoodCourt', 'ShoppingMall', 'VRDeck', 'RoomService', 'Spa'], 'Spa')\n",
    "RandomForestImpute(train, ['Age', 'FoodCourt', 'ShoppingMall', 'Spa', 'RoomService', 'VRDeck'], 'VRDeck')\n",
    "RandomForestImpute(test, ['Age', 'FoodCourt', 'ShoppingMall', 'Spa', 'RoomService', 'VRDeck'], 'VRDeck')\n",
    "RandomForestImpute(train, ['Age', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'value2'], 'value2')\n",
    "RandomForestImpute(test, ['Age', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'value2'], 'value2')\n",
    "fill_na_median(train, 'FoodCourt')\n",
    "fill_na_median(test, 'FoodCourt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:13:10.778066Z",
     "start_time": "2024-09-12T14:13:10.764453Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEST ET CATEGORİK\n",
    "\n",
    "# Ordinal Encoding for string columns\n",
    "# oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Find all string columns\n",
    "# string_cols = test.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Loop over all string columns and encode them\n",
    "# for col in string_cols:\n",
    "#     if col==\"VIP\":\n",
    "#         print(\"\")\n",
    "#     else:\n",
    "#         train[col] = train[col].astype(str)\n",
    "#         test[col] = test[col].astype(str)\n",
    "        \n",
    "#         Fit OrdinalEncoder\n",
    "#         train[[col]] = oe.fit_transform(train[[col]])\n",
    "#         test[[col]] = oe.transform(test[[col]])\n",
    "\n",
    "# print(train[\"VIP\"].isnull().sum())\n",
    "# Copy the original data\n",
    "# trainData = train.copy()\n",
    "# testData = test.copy()\n",
    "# Ordinal Encoding for string columns\n",
    "# oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Find all string columns\n",
    "# string_cols = test.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Loop over all string columns and encode them\n",
    "# for col in string_cols:\n",
    "#     if col==\"VIP\":\n",
    "#         print(\"\")\n",
    "#     else:\n",
    "#         train[col] = train[col].astype(str)\n",
    "#         test[col] = test[col].astype(str)\n",
    "        \n",
    "#         Fit OrdinalEncoder\n",
    "#         train[[col]] = oe.fit_transform(train[[col]])\n",
    "#         test[[col]] = oe.transform(test[[col]])\n",
    "# print(train[\"VIP\"].isnull().sum())\n",
    "\n",
    "# Imputation functions\n",
    "# def fill_na_forward(data, col):\n",
    "#     data[col]=train[col]\n",
    "#     print(train[\"VIP\"].isnull().sum())  \n",
    "#     data[col] = data[col].ffill()\n",
    "\n",
    "# def fill_na_backward(data, col):\n",
    "#     data[col]=train[col]\n",
    "#     print(train[\"VIP\"].isnull().sum())   \n",
    "#     data[col] = data[col].bfill()\n",
    "\n",
    "# def fill_na_mode(data, col):\n",
    "#     data[col]=train[col]\n",
    "#     print(train[\"VIP\"].isnull().sum())\n",
    "#     mode_value = data[col].mode()[0]\n",
    "#     data[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "# def interpolate_values(data, col):\n",
    "#     data[col]=train[col]\n",
    "#     print(train[col].isnull().sum())\n",
    "#     data[col] = data[col].interpolate(method='linear')\n",
    "\n",
    "# def knn_imputation(data, target_cols):\n",
    "#     data[col]=train[col]\n",
    "#     print(train[\"VIP\"].isnull().sum())\n",
    "#     \"\"\"\n",
    "#     Perform K-Nearest Neighbors Imputation on the target columns.\n",
    "#     \"\"\"\n",
    "#     knn = KNNImputer()\n",
    "#     data[target_cols] = knn.fit_transform(data[target_cols])\n",
    "\n",
    "# List of imputation methods\n",
    "# imputation_methods = [\n",
    "#     fill_na_forward,\n",
    "#     fill_na_backward,\n",
    "#     fill_na_mode,\n",
    "#     interpolate_values,\n",
    "#     knn_imputation\n",
    "# ]\n",
    "\n",
    "# def apply_ml_and_report(data, target, method_name):\n",
    "#     \"\"\"\n",
    "#     This function sets up the AutoML pipeline using the imputed data and trains\n",
    "#     the model to get the performance score.\n",
    "#     \"\"\"\n",
    "#     Run AutoML using pycaret\n",
    "#     clf = setup(data, target=target, html=False,random_state=41)\n",
    "#     best_model = compare_models()\n",
    "\n",
    "#     Print or log the result along with the imputation method\n",
    "#     print(f\"VIP column imputed with {method_name}, best model: {best_model}\")\n",
    "\n",
    "# Loop through each method and apply it to the VIP column, then run AutoML on the Transported column\n",
    "# for method in imputation_methods:\n",
    "#     Copy the data for each iteration to keep the imputations isolated\n",
    "#     data_copy = trainData.copy()\n",
    "\n",
    "#     Name of the current method for logging\n",
    "#     method_name = method.__name__\n",
    "\n",
    "#     Try to apply the imputation method\n",
    "#     try:\n",
    "#         Impute the \"VIP\" column\n",
    "#         Bu column yerine verilen columnu yazıcaksınız\n",
    "#         target_col = 'VIP'\n",
    "        \n",
    "#         if method_name == \"knn_imputation\":\n",
    "#             target_features = ['HomePlanet', 'CryoSleep', 'Destination', 'value1', 'value3', 'Transported']\n",
    "#             knn_imputation(data_copy, target_features)  # Apply KNNImputer on selected columns\n",
    "#         else:\n",
    "#             method(data_copy, target_col)  # Apply other imputation methods\n",
    "            \n",
    "\n",
    "#         Now apply AutoML to the \"Transported\" column\n",
    "#         apply_ml_and_report(data_copy, \"Transported\", method_name)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred with method {method_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:13:10.793924Z",
     "start_time": "2024-09-12T14:13:10.780066Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "train=train.iloc[:5000]\n",
    "X_train = train.drop(columns=[\"TARGET\"]) \n",
    "X_test = test                              \n",
    "y_train = train[\"TARGET\"]    \n",
    "\n",
    "\n",
    "transformers.logging.get_verbosity = lambda: logging.NOTSET\n",
    "transformers.logging.get_verbosity()\n",
    "\n",
    "clf1=setup(train, target=\"TARGET\",html=False)\n",
    "best_model=compare_models()\n",
    "#The best model is XGBBoost, for now :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:13:10.809416Z",
     "start_time": "2024-09-12T14:13:10.795104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((878594, 110), (585730, 109))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Verinizi işleyin (datetime sütunlarını ayrıştırın)\n",
    "#train = process_datetime_features(train)\n",
    "#test = process_datetime_features(test)\n",
    "\n",
    "# Hedef ve özellikleri ayırın\n",
    "y = train[\"TARGET\"]\n",
    "X = train.drop(columns=[\"TARGET\"], axis=1)\n",
    "\n",
    "\n",
    "# Repeated K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=24)\n",
    "scores = []\n",
    "test_preds = np.zeros(len(test))  # Test setinizin boyutuna göre ayarlayın\n",
    "\n",
    "# Model parametreleri\n",
    "param = {\n",
    "    'iterations': 456,\n",
    "    'depth': 4,\n",
    "    'learning_rate': 0.017250413325681634,\n",
    "    'random_strength': 8,\n",
    "    'bagging_temperature': 0.5608982636794247,\n",
    "    'border_count': 208,\n",
    "    'l2_leaf_reg': 9.268604139004962,\n",
    "    'early_stopping_rounds': 50,  # Erken durdurma\n",
    "    'verbose': 100\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # CatBoost Regressor modelini oluştur\n",
    "    model = CatBoostRegressor(**param, random_state=41)\n",
    "\n",
    "    # Modeli eğit\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True)\n",
    "\n",
    "    # Tahminler yap\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # RMSE hesapla\n",
    "    score = mean_squared_error(y_val, y_pred, squared=False)  # RMSE\n",
    "    scores.append(score)\n",
    "\n",
    "    print(f\"Fold {fold + 1}: RMSE = {score:.4f}\")\n",
    "\n",
    "    # Test seti için ortalama tahminler al\n",
    "    test_preds += model.predict(test) / kf.n_splits\n",
    "\n",
    "# Ortalama RMSE\n",
    "mean_score = np.mean(scores)\n",
    "print(f\"Ortalama RMSE = {mean_score:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import shap\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Özellik ölçeklendirme (isteğe bağlı)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y = train[\"TARGET\"]\n",
    "X = train.drop(columns=[\"TARGET\"], axis=1)\n",
    "\n",
    "param = {\n",
    "    \"iterations\": 163,\n",
    "    \"depth\": 5,\n",
    "    \"learning_rate\": 0.4330894758291788,\n",
    "    \"random_strength\": 9,\n",
    "    \"bagging_temperature\": 0.07827553008007726,\n",
    "    \"border_count\": 96,\n",
    "    \"l2_leaf_reg\": 4.5286949510996,\n",
    "}\n",
    "\n",
    "# Repeated K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=24)\n",
    "scores = []\n",
    "test_preds = np.zeros(len(test))  # Assuming `test` is your test set\n",
    "\n",
    "# SHAP değerlerini saklayacağımız liste\n",
    "all_shap_values = []\n",
    "X_all_train = []\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create and train CatBoostRegressor model\n",
    "    model = CatBoostRegressor(**param, random_state=41, verbose=False)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE score\n",
    "    score = mean_squared_error(y_test, y_pred, squared=False)  # RMSE\n",
    "    scores.append(score)\n",
    "\n",
    "    print(f\"Fold {fold + 1}: RMSE = {score:.4f}\")\n",
    "\n",
    "    # SHAP değerlerini her fold için hesapla\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "    # SHAP değerlerini ve X_train'i bir listede sakla\n",
    "    all_shap_values.append(shap_values)\n",
    "    X_all_train.append(X_train)\n",
    "\n",
    "    # Average test set predictions across folds\n",
    "    test_preds += model.predict(test) / kf.n_splits\n",
    "\n",
    "# Calculate average RMSE score\n",
    "mean_score = np.mean(scores)\n",
    "print(f\"Average RMSE = {mean_score:.4f}\")\n",
    "\n",
    "# Tüm SHAP değerlerini ve X_train'leri birleştir\n",
    "combined_shap_values = np.concatenate(all_shap_values, axis=0)\n",
    "combined_X_train = pd.concat(X_all_train)\n",
    "\n",
    "# SHAP değerlerini görselleştir\n",
    "shap.summary_plot(combined_shap_values, combined_X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "shap.summary_plot(combined_shap_values, combined_X_train, max_display=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# SHAP değerlerinin ortalamasını (mutlak değerde) hesapla\n",
    "shap_values_mean = np.mean(np.abs(combined_shap_values), axis=0)\n",
    "\n",
    "# Özellik isimlerini al\n",
    "feature_names = combined_X_train.columns\n",
    "\n",
    "# SHAP değerlerinin ortalamasını ve isimleri bir DataFrame'e ekle\n",
    "shap_summary = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean_SHAP_Value': shap_values_mean\n",
    "})\n",
    "\n",
    "# SHAP değerlerine göre artan şekilde sıralama yap ve en önemsiz 5 özelliği al\n",
    "least_important_features = shap_summary.sort_values(by='Mean_SHAP_Value').head(30)\n",
    "\n",
    "# En önemsiz 5 özelliği göster\n",
    "print(least_important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "least_important_features[\"SİLİNECEKFUTURE\"]=least_important_features[\"Feature\"]\n",
    "least_important_features.to_csv(\"SİLİNECEKLER.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "shap.waterfall_plot(shap.Explanation(values=combined_shap_values[0], base_values=explainer.expected_value, data=combined_X_train.iloc[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# # Prepare your data\n",
    "y = train[\"TARGET\"]\n",
    "X = train.drop(columns=[\"TARGET\"])\n",
    "test_preds = np.zeros(len(test))  # Assuming `test` is your test set\n",
    "\n",
    "def objective(trial):\n",
    "     # Define the hyperparameters to tune\n",
    "     param = {\n",
    "         'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "         'depth': trial.suggest_int('depth', 1, 16),\n",
    "         'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n",
    "         'random_strength': trial.suggest_int('random_strength', 1, 20),\n",
    "         'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "         'border_count': trial.suggest_int('border_count', 50, 255),\n",
    "         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.01, 10.0),\n",
    "         'early_stopping_rounds': trial.suggest_int('early_stopping_rounds',0,700),\n",
    "         'random_state': 42\n",
    "     }\n",
    "\n",
    "     # Repeated K-Fold cross-validation\n",
    "     kf = KFold(n_splits=5, shuffle=True, random_state=24)\n",
    "     scores = []\n",
    "\n",
    "     for train_index, test_index in kf.split(X, y):\n",
    "         X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "         y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "         # Create and train CatBoostClassifier model with parameters\n",
    "         model = CatBoostRegressor(**param, verbose=False)\n",
    "         model.fit(X_train, y_train)\n",
    "\n",
    "         # Predict and calculate accuracy\n",
    "         y_pred = model.predict(X_test)\n",
    "         score = mean_squared_error(y_test, y_pred)\n",
    "         scores.append(score)\n",
    "\n",
    "     # Calculate the mean of the scores\n",
    "     mean_score = np.mean(scores)\n",
    "     return mean_score\n",
    "\n",
    " # Create a study object and specify the direction of the optimization\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=5)  # Specify the number of trials\n",
    "\n",
    "# # Best hyperparameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# # You can retrain your model on the full training set using\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
